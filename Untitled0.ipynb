{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPP3HXRXKMw/T9J5F/+aDiv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexFRD77/ludwig44/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_kFMY0Z4F8P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6c6bd5c6-e599-4d2f-a5e2-2514fdec61e5"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH5NmLC1Da-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# скрипт создан через google colab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhZ0bzj15PW2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "fd99e73f-b043-43eb-88d2-0fc91865f196"
      },
      "source": [
        "pip install pandas"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkAwpQ9q5XoG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a164c8a4-7df5-4bbf-b275-418af1c0aecb"
      },
      "source": [
        "pip install ludwig"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ludwig\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/b6/8c5d8ee36997f31c1e9756b5ebb83d942f21e79287453cd525eac46e5801/ludwig-0.2.2.7.tar.gz (172kB)\n",
            "\r\u001b[K     |██                              | 10kB 26.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 30kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 51kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 61kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 71kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 81kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 92kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 102kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 112kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 122kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 133kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 143kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 153kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 163kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.25 in /usr/local/lib/python3.6/dist-packages (from ludwig) (0.29.19)\n",
            "Requirement already satisfied: h5py>=2.6 in /usr/local/lib/python3.6/dist-packages (from ludwig) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from ludwig) (1.18.5)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.6/dist-packages (from ludwig) (1.0.4)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.6/dist-packages (from ludwig) (1.4.1)\n",
            "Requirement already satisfied: tabulate>=0.7 in /usr/local/lib/python3.6/dist-packages (from ludwig) (0.8.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from ludwig) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from ludwig) (4.41.1)\n",
            "Collecting tensorflow==1.15.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/36/9a02e27f0ec248b676a380ffe910c1858e3af3027c0d4d513dd0b56a5613/tensorflow-1.15.3-cp36-cp36m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 94kB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from ludwig) (3.13)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from ludwig) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py>=2.6->ludwig) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->ludwig) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->ludwig) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->ludwig) (0.15.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 51.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.3->ludwig) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.3->ludwig) (3.10.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 55.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.3->ludwig) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.3->ludwig) (3.2.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.3->ludwig) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.3->ludwig) (1.29.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.3->ludwig) (1.12.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.3->ludwig) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.3->ludwig) (0.8.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.3->ludwig) (1.1.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3->ludwig) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3->ludwig) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3->ludwig) (47.1.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3->ludwig) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3->ludwig) (3.1.0)\n",
            "Building wheels for collected packages: ludwig, gast\n",
            "  Building wheel for ludwig (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ludwig: filename=ludwig-0.2.2.7-cp36-none-any.whl size=236245 sha256=9ddb53c823a67e2004e04206f6f261e10f97bc14eca5a74cfce2871da31d7b10\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/f3/49/074f3056cf991866d89b5893e6e427573cd169c387087d2230\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=8f21a475622ee560c20c94cd09f3c4304a3cca381e255fb9ea55a02593e68f95\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built ludwig gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, gast, tensorflow, ludwig\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed gast-0.2.2 ludwig-0.2.2.7 tensorboard-1.15.0 tensorflow-1.15.3 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wy6-45953e1",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "c57e1153-2eec-4dfe-a110-dd1a39b5d707"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-09b4fafb-6a14-417e-bd2c-daa6962115c4\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-09b4fafb-6a14-417e-bd2c-daa6962115c4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving luda.csv to luda.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXu6ANhj6ak0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ludwig.api import *\n",
        "import pandas as pd\n",
        "#from ludwig.visualise import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtOJ8dw46y44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SkinCancer=pd.read_csv(\"luda.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THeRw8SM7PsE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "38794062-ec78-4d24-95ed-91a6afc4bb7b"
      },
      "source": [
        "SkinCancer.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     lesion_id      image_id   dx dx_type   age   sex localization\n",
              "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
              "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
              "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
              "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
              "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4_ftnNM7cb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_definition = {\n",
        "    \"input_features\": [\n",
        "        {\"name\": \"age\",\"type\": \"numerical\"},\n",
        "        {\"name\": \"sex\",\"type\": \"category\"},\n",
        "        {\"name\": \"localization\", \"type\": \"category\"}\n",
        "    ],\n",
        "    \"output_features\": [\n",
        "        {\"name\": \"dx\", \"type\": \"category\"}\n",
        "    ]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT5heS8u7jF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# попробуем построить модель, которая на основе данных о возрасте,\n",
        "#поле илокализации рака кожи могла бы предсказывать тип рака"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-waoFfYq7n39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LudwigModel(model_definition)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1uQD_Ds7s6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_stats = model.train(SkinCancer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXeacOw973fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"ШАУРМА для веганов\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw2dmurE8AST",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "565cff9a-0844-4308-c1a6-a5922225af6d"
      },
      "source": [
        "train_stats"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test': OrderedDict([('dx',\n",
              "               OrderedDict([('loss',\n",
              "                             [15.242925699248568,\n",
              "                              8.86271519163486,\n",
              "                              5.764864863815502,\n",
              "                              4.732646105428992,\n",
              "                              3.801427983873673,\n",
              "                              2.92887946946627,\n",
              "                              2.2974070774689888,\n",
              "                              1.9259777855327112,\n",
              "                              1.6267027177883469,\n",
              "                              1.433478825692912,\n",
              "                              1.345428016410226,\n",
              "                              1.2876591359689338,\n",
              "                              1.2402279395183533,\n",
              "                              1.1994886073144033,\n",
              "                              1.1638957948175095,\n",
              "                              1.1326233958470002,\n",
              "                              1.1051349513706663,\n",
              "                              1.0810133489943643,\n",
              "                              1.0598976115840688,\n",
              "                              1.0414610282762056,\n",
              "                              1.025403742511157,\n",
              "                              1.0114528141555592,\n",
              "                              0.9993600704591086,\n",
              "                              0.9889002229724525,\n",
              "                              0.9798681438727537,\n",
              "                              0.9720772740798446,\n",
              "                              0.9653587632506858,\n",
              "                              0.9595616163491596,\n",
              "                              0.9545527509150614,\n",
              "                              0.9502163777824577,\n",
              "                              0.9464529644138637,\n",
              "                              0.9431779080068186,\n",
              "                              0.9403193621841702,\n",
              "                              0.9378170644357308,\n",
              "                              0.9356201482486483,\n",
              "                              0.9336857968007638,\n",
              "                              0.9319779209204909,\n",
              "                              0.9304662786973948,\n",
              "                              0.9291250000776529,\n",
              "                              0.9279322490740671,\n",
              "                              0.926869597689796,\n",
              "                              0.9259211105851424,\n",
              "                              0.9250730664978803,\n",
              "                              0.9243139533899516,\n",
              "                              0.9236334764320432,\n",
              "                              0.9230228482311919,\n",
              "                              0.9224745704320855,\n",
              "                              0.921981791139559,\n",
              "                              0.9215387523932614,\n",
              "                              0.9211401990351786,\n",
              "                              0.9207817048516892,\n",
              "                              0.9204591581232978,\n",
              "                              0.9201690033191943,\n",
              "                              0.9199081391778611,\n",
              "                              0.9196736469220266,\n",
              "                              0.91946299409745,\n",
              "                              0.9192739112989896,\n",
              "                              0.9191044115838204,\n",
              "                              0.9189526390483361,\n",
              "                              0.9188169202731766,\n",
              "                              0.9186958031496626,\n",
              "                              0.9185879268112377,\n",
              "                              0.9184921177288958,\n",
              "                              0.9184072518773359,\n",
              "                              0.9183322741481791,\n",
              "                              0.918266409954042,\n",
              "                              0.9182087789055046,\n",
              "                              0.9181585928259308,\n",
              "                              0.9181152722307744,\n",
              "                              0.91807812892147,\n",
              "                              0.9180466494184111,\n",
              "                              0.918020256178373,\n",
              "                              0.9179985881155077,\n",
              "                              0.9179811725179657,\n",
              "                              0.9179675395858804,\n",
              "                              0.9179574602432833,\n",
              "                              0.9179504452770902,\n",
              "                              0.9179464578021878,\n",
              "                              0.9179448911555244,\n",
              "                              0.9179458948188762,\n",
              "                              0.9179489883151066,\n",
              "                              0.917953897917847,\n",
              "                              0.917960658570889,\n",
              "                              0.9179688907458279,\n",
              "                              0.9179786177385247,\n",
              "                              0.917989541556089,\n",
              "                              0.9180016068708502,\n",
              "                              0.9180147127340769,\n",
              "                              0.9180286883094535,\n",
              "                              0.9180434967118668,\n",
              "                              0.9180589845768975,\n",
              "                              0.9180750752223357,\n",
              "                              0.9180917375870333,\n",
              "                              0.918108867810276,\n",
              "                              0.9181264163883588,\n",
              "                              0.9181443134336981,\n",
              "                              0.9181624395550055,\n",
              "                              0.9181808927890301,\n",
              "                              0.9181995809229883,\n",
              "                              0.9182183670936953]),\n",
              "                            ('accuracy',\n",
              "                             [0.004580152671755725,\n",
              "                              0.014249363867684479,\n",
              "                              0.571501272264631,\n",
              "                              0.6346055979643765,\n",
              "                              0.6366412213740458,\n",
              "                              0.6351145038167939,\n",
              "                              0.6356234096692112,\n",
              "                              0.6458015267175573,\n",
              "                              0.6493638676844784,\n",
              "                              0.6442748091603053,\n",
              "                              0.6391857506361324,\n",
              "                              0.6493638676844784,\n",
              "                              0.6549618320610687,\n",
              "                              0.6661577608142494,\n",
              "                              0.6717557251908397,\n",
              "                              0.6743002544529262,\n",
              "                              0.6788804071246819,\n",
              "                              0.6829516539440204,\n",
              "                              0.6875318066157761,\n",
              "                              0.6900763358778625,\n",
              "                              0.6900763358778625,\n",
              "                              0.6900763358778625,\n",
              "                              0.6900763358778625,\n",
              "                              0.6895674300254453,\n",
              "                              0.6905852417302799,\n",
              "                              0.6921119592875318,\n",
              "                              0.694147582697201,\n",
              "                              0.6951653944020356,\n",
              "                              0.6972010178117048,\n",
              "                              0.6972010178117048,\n",
              "                              0.6972010178117048,\n",
              "                              0.6977099236641221,\n",
              "                              0.6977099236641221,\n",
              "                              0.6946564885496184,\n",
              "                              0.6946564885496184,\n",
              "                              0.6956743002544529,\n",
              "                              0.6972010178117048,\n",
              "                              0.6972010178117048,\n",
              "                              0.6972010178117048,\n",
              "                              0.6972010178117048,\n",
              "                              0.6972010178117048,\n",
              "                              0.6972010178117048,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6972010178117048,\n",
              "                              0.6982188295165395,\n",
              "                              0.6982188295165395,\n",
              "                              0.6982188295165395,\n",
              "                              0.6982188295165395,\n",
              "                              0.6982188295165395,\n",
              "                              0.6982188295165395,\n",
              "                              0.6982188295165395,\n",
              "                              0.6982188295165395,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6972010178117048,\n",
              "                              0.6972010178117048,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6966921119592875,\n",
              "                              0.6997455470737913,\n",
              "                              0.6997455470737913,\n",
              "                              0.6997455470737913,\n",
              "                              0.6997455470737913,\n",
              "                              0.6997455470737913,\n",
              "                              0.6997455470737913,\n",
              "                              0.6997455470737913,\n",
              "                              0.6982188295165395,\n",
              "                              0.6982188295165395,\n",
              "                              0.6982188295165395,\n",
              "                              0.6982188295165395,\n",
              "                              0.6982188295165395,\n",
              "                              0.6982188295165395,\n",
              "                              0.6982188295165395,\n",
              "                              0.6982188295165395,\n",
              "                              0.6982188295165395,\n",
              "                              0.6987277353689567,\n",
              "                              0.6987277353689567,\n",
              "                              0.6992366412213741,\n",
              "                              0.6992366412213741,\n",
              "                              0.6992366412213741,\n",
              "                              0.6992366412213741]),\n",
              "                            ('hits_at_k',\n",
              "                             [0.7633587786259542,\n",
              "                              0.7648854961832061,\n",
              "                              0.7643765903307888,\n",
              "                              0.7638676844783715,\n",
              "                              0.7633587786259542,\n",
              "                              0.76793893129771,\n",
              "                              0.7994910941475827,\n",
              "                              0.8157760814249364,\n",
              "                              0.8193384223918575,\n",
              "                              0.8229007633587786,\n",
              "                              0.8422391857506362,\n",
              "                              0.8564885496183207,\n",
              "                              0.8636132315521629,\n",
              "                              0.8702290076335878,\n",
              "                              0.8732824427480916,\n",
              "                              0.8732824427480916,\n",
              "                              0.8732824427480916,\n",
              "                              0.870737913486005,\n",
              "                              0.872264631043257,\n",
              "                              0.872264631043257,\n",
              "                              0.8732824427480916,\n",
              "                              0.8783715012722646,\n",
              "                              0.8768447837150127,\n",
              "                              0.8783715012722646,\n",
              "                              0.8819338422391858,\n",
              "                              0.8849872773536895,\n",
              "                              0.8844783715012723,\n",
              "                              0.8865139949109415,\n",
              "                              0.8875318066157761,\n",
              "                              0.8875318066157761,\n",
              "                              0.8885496183206106,\n",
              "                              0.8926208651399491,\n",
              "                              0.8936386768447837,\n",
              "                              0.8951653944020356,\n",
              "                              0.8926208651399491,\n",
              "                              0.8926208651399491,\n",
              "                              0.8936386768447837,\n",
              "                              0.8921119592875318,\n",
              "                              0.8931297709923665,\n",
              "                              0.8926208651399491,\n",
              "                              0.8931297709923665,\n",
              "                              0.8931297709923665,\n",
              "                              0.8931297709923665,\n",
              "                              0.8931297709923665,\n",
              "                              0.8926208651399491,\n",
              "                              0.8921119592875318,\n",
              "                              0.8926208651399491,\n",
              "                              0.8931297709923665,\n",
              "                              0.8946564885496183,\n",
              "                              0.8966921119592876,\n",
              "                              0.8972010178117048,\n",
              "                              0.8977099236641222,\n",
              "                              0.8961832061068702,\n",
              "                              0.8966921119592876,\n",
              "                              0.8972010178117048,\n",
              "                              0.8972010178117048,\n",
              "                              0.8972010178117048,\n",
              "                              0.8961832061068702,\n",
              "                              0.8961832061068702,\n",
              "                              0.8961832061068702,\n",
              "                              0.8961832061068702,\n",
              "                              0.8956743002544529,\n",
              "                              0.8966921119592876,\n",
              "                              0.8966921119592876,\n",
              "                              0.8966921119592876,\n",
              "                              0.8966921119592876,\n",
              "                              0.8961832061068702,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8951653944020356,\n",
              "                              0.8946564885496183,\n",
              "                              0.8946564885496183,\n",
              "                              0.8946564885496183,\n",
              "                              0.8946564885496183,\n",
              "                              0.8946564885496183,\n",
              "                              0.8946564885496183,\n",
              "                              0.8946564885496183,\n",
              "                              0.8946564885496183,\n",
              "                              0.8946564885496183,\n",
              "                              0.8946564885496183])])),\n",
              "              ('combined',\n",
              "               {'accuracy': [0.004580152671755725,\n",
              "                 0.014249363867684479,\n",
              "                 0.571501272264631,\n",
              "                 0.6346055979643765,\n",
              "                 0.6366412213740458,\n",
              "                 0.6351145038167939,\n",
              "                 0.6356234096692112,\n",
              "                 0.6458015267175573,\n",
              "                 0.6493638676844784,\n",
              "                 0.6442748091603053,\n",
              "                 0.6391857506361324,\n",
              "                 0.6493638676844784,\n",
              "                 0.6549618320610687,\n",
              "                 0.6661577608142494,\n",
              "                 0.6717557251908397,\n",
              "                 0.6743002544529262,\n",
              "                 0.6788804071246819,\n",
              "                 0.6829516539440204,\n",
              "                 0.6875318066157761,\n",
              "                 0.6900763358778625,\n",
              "                 0.6900763358778625,\n",
              "                 0.6900763358778625,\n",
              "                 0.6900763358778625,\n",
              "                 0.6895674300254453,\n",
              "                 0.6905852417302799,\n",
              "                 0.6921119592875318,\n",
              "                 0.694147582697201,\n",
              "                 0.6951653944020356,\n",
              "                 0.6972010178117048,\n",
              "                 0.6972010178117048,\n",
              "                 0.6972010178117048,\n",
              "                 0.6977099236641221,\n",
              "                 0.6977099236641221,\n",
              "                 0.6946564885496184,\n",
              "                 0.6946564885496184,\n",
              "                 0.6956743002544529,\n",
              "                 0.6972010178117048,\n",
              "                 0.6972010178117048,\n",
              "                 0.6972010178117048,\n",
              "                 0.6972010178117048,\n",
              "                 0.6972010178117048,\n",
              "                 0.6972010178117048,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6972010178117048,\n",
              "                 0.6982188295165395,\n",
              "                 0.6982188295165395,\n",
              "                 0.6982188295165395,\n",
              "                 0.6982188295165395,\n",
              "                 0.6982188295165395,\n",
              "                 0.6982188295165395,\n",
              "                 0.6982188295165395,\n",
              "                 0.6982188295165395,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6972010178117048,\n",
              "                 0.6972010178117048,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6966921119592875,\n",
              "                 0.6997455470737913,\n",
              "                 0.6997455470737913,\n",
              "                 0.6997455470737913,\n",
              "                 0.6997455470737913,\n",
              "                 0.6997455470737913,\n",
              "                 0.6997455470737913,\n",
              "                 0.6997455470737913,\n",
              "                 0.6982188295165395,\n",
              "                 0.6982188295165395,\n",
              "                 0.6982188295165395,\n",
              "                 0.6982188295165395,\n",
              "                 0.6982188295165395,\n",
              "                 0.6982188295165395,\n",
              "                 0.6982188295165395,\n",
              "                 0.6982188295165395,\n",
              "                 0.6982188295165395,\n",
              "                 0.6987277353689567,\n",
              "                 0.6987277353689567,\n",
              "                 0.6992366412213741,\n",
              "                 0.6992366412213741,\n",
              "                 0.6992366412213741,\n",
              "                 0.6992366412213741],\n",
              "                'loss': [15.242925699248568,\n",
              "                 8.86271519163486,\n",
              "                 5.764864863815502,\n",
              "                 4.732646105428992,\n",
              "                 3.801427983873673,\n",
              "                 2.92887946946627,\n",
              "                 2.2974070774689888,\n",
              "                 1.9259777855327112,\n",
              "                 1.6267027177883469,\n",
              "                 1.433478825692912,\n",
              "                 1.345428016410226,\n",
              "                 1.2876591359689338,\n",
              "                 1.2402279395183533,\n",
              "                 1.1994886073144033,\n",
              "                 1.1638957948175095,\n",
              "                 1.1326233958470002,\n",
              "                 1.1051349513706663,\n",
              "                 1.0810133489943643,\n",
              "                 1.0598976115840688,\n",
              "                 1.0414610282762056,\n",
              "                 1.025403742511157,\n",
              "                 1.0114528141555592,\n",
              "                 0.9993600704591086,\n",
              "                 0.9889002229724525,\n",
              "                 0.9798681438727537,\n",
              "                 0.9720772740798446,\n",
              "                 0.9653587632506858,\n",
              "                 0.9595616163491596,\n",
              "                 0.9545527509150614,\n",
              "                 0.9502163777824577,\n",
              "                 0.9464529644138637,\n",
              "                 0.9431779080068186,\n",
              "                 0.9403193621841702,\n",
              "                 0.9378170644357308,\n",
              "                 0.9356201482486483,\n",
              "                 0.9336857968007638,\n",
              "                 0.9319779209204909,\n",
              "                 0.9304662786973948,\n",
              "                 0.9291250000776529,\n",
              "                 0.9279322490740671,\n",
              "                 0.926869597689796,\n",
              "                 0.9259211105851424,\n",
              "                 0.9250730664978803,\n",
              "                 0.9243139533899516,\n",
              "                 0.9236334764320432,\n",
              "                 0.9230228482311919,\n",
              "                 0.9224745704320855,\n",
              "                 0.921981791139559,\n",
              "                 0.9215387523932614,\n",
              "                 0.9211401990351786,\n",
              "                 0.9207817048516892,\n",
              "                 0.9204591581232978,\n",
              "                 0.9201690033191943,\n",
              "                 0.9199081391778611,\n",
              "                 0.9196736469220266,\n",
              "                 0.91946299409745,\n",
              "                 0.9192739112989896,\n",
              "                 0.9191044115838204,\n",
              "                 0.9189526390483361,\n",
              "                 0.9188169202731766,\n",
              "                 0.9186958031496626,\n",
              "                 0.9185879268112377,\n",
              "                 0.9184921177288958,\n",
              "                 0.9184072518773359,\n",
              "                 0.9183322741481791,\n",
              "                 0.918266409954042,\n",
              "                 0.9182087789055046,\n",
              "                 0.9181585928259308,\n",
              "                 0.9181152722307744,\n",
              "                 0.91807812892147,\n",
              "                 0.9180466494184111,\n",
              "                 0.918020256178373,\n",
              "                 0.9179985881155077,\n",
              "                 0.9179811725179657,\n",
              "                 0.9179675395858804,\n",
              "                 0.9179574602432833,\n",
              "                 0.9179504452770902,\n",
              "                 0.9179464578021878,\n",
              "                 0.9179448911555244,\n",
              "                 0.9179458948188762,\n",
              "                 0.9179489883151066,\n",
              "                 0.917953897917847,\n",
              "                 0.917960658570889,\n",
              "                 0.9179688907458279,\n",
              "                 0.9179786177385247,\n",
              "                 0.917989541556089,\n",
              "                 0.9180016068708502,\n",
              "                 0.9180147127340769,\n",
              "                 0.9180286883094535,\n",
              "                 0.9180434967118668,\n",
              "                 0.9180589845768975,\n",
              "                 0.9180750752223357,\n",
              "                 0.9180917375870333,\n",
              "                 0.918108867810276,\n",
              "                 0.9181264163883588,\n",
              "                 0.9181443134336981,\n",
              "                 0.9181624395550055,\n",
              "                 0.9181808927890301,\n",
              "                 0.9181995809229883,\n",
              "                 0.9182183670936953]})]),\n",
              " 'training': OrderedDict([('dx',\n",
              "               OrderedDict([('loss',\n",
              "                             [14.667233671441704,\n",
              "                              8.388423603660971,\n",
              "                              5.377235209061436,\n",
              "                              4.412309341837736,\n",
              "                              3.5438300917169347,\n",
              "                              2.730825896076994,\n",
              "                              2.1499660634418714,\n",
              "                              1.8047805631873783,\n",
              "                              1.5264882144215601,\n",
              "                              1.3515812960343225,\n",
              "                              1.2732222647320117,\n",
              "                              1.2199064328140905,\n",
              "                              1.1760733330460686,\n",
              "                              1.1385710827924669,\n",
              "                              1.105920953919331,\n",
              "                              1.0773412173666737,\n",
              "                              1.0523343106328487,\n",
              "                              1.0305173510214278,\n",
              "                              1.011555421824403,\n",
              "                              0.9951385009559947,\n",
              "                              0.9809754373517742,\n",
              "                              0.9687963816196321,\n",
              "                              0.9583533902209784,\n",
              "                              0.949420519740151,\n",
              "                              0.9417926688704454,\n",
              "                              0.9352845885853391,\n",
              "                              0.9297305350556732,\n",
              "                              0.9249844431910612,\n",
              "                              0.9209194552928536,\n",
              "                              0.917426989072496,\n",
              "                              0.9144152122011214,\n",
              "                              0.9118071837024855,\n",
              "                              0.9095387950234117,\n",
              "                              0.9075567818062923,\n",
              "                              0.9058171298791103,\n",
              "                              0.9042831748698876,\n",
              "                              0.9029245855968275,\n",
              "                              0.9017161996268851,\n",
              "                              0.9006369798848282,\n",
              "                              0.8996693461974395,\n",
              "                              0.8987986300306955,\n",
              "                              0.898012402820239,\n",
              "                              0.8973002103030497,\n",
              "                              0.8966531408064086,\n",
              "                              0.8960635949305957,\n",
              "                              0.8955251762820776,\n",
              "                              0.8950322340526329,\n",
              "                              0.8945799497900568,\n",
              "                              0.8941640845847512,\n",
              "                              0.8937809962096157,\n",
              "                              0.8934274805760457,\n",
              "                              0.8931006946044168,\n",
              "                              0.892798210857491,\n",
              "                              0.8925177068798704,\n",
              "                              0.8922572351513,\n",
              "                              0.8920150763263397,\n",
              "                              0.8917895924740379,\n",
              "                              0.8915793406297169,\n",
              "                              0.8913831252858934,\n",
              "                              0.8911996855892448,\n",
              "                              0.8910280627770493,\n",
              "                              0.8908672659492868,\n",
              "                              0.8907164038315613,\n",
              "                              0.8905747608333717,\n",
              "                              0.8904415581608649,\n",
              "                              0.89031618199165,\n",
              "                              0.8901980945616081,\n",
              "                              0.8900865502854272,\n",
              "                              0.889981253499966,\n",
              "                              0.8898816964359171,\n",
              "                              0.8897874613084072,\n",
              "                              0.889698088554076,\n",
              "                              0.88961331464708,\n",
              "                              0.8895327839346556,\n",
              "                              0.8894562425321489,\n",
              "                              0.8893833251456068,\n",
              "                              0.8893138646610799,\n",
              "                              0.8892475868402924,\n",
              "                              0.8891842527959963,\n",
              "                              0.8891237489764057,\n",
              "                              0.8890658654178404,\n",
              "                              0.8890103653755391,\n",
              "                              0.8889571524376081,\n",
              "                              0.8889060627038275,\n",
              "                              0.8888569986910607,\n",
              "                              0.8888098329213588,\n",
              "                              0.8887643725709344,\n",
              "                              0.8887205908587058,\n",
              "                              0.8886783699479139,\n",
              "                              0.8886376102129351,\n",
              "                              0.8885982398804705,\n",
              "                              0.8885601925334379,\n",
              "                              0.8885233910423221,\n",
              "                              0.8884876897180392,\n",
              "                              0.8884531667613474,\n",
              "                              0.8884196186360266,\n",
              "                              0.8883870903342937,\n",
              "                              0.8883555165103098,\n",
              "                              0.8883248361032084,\n",
              "                              0.8882949687697451]),\n",
              "                            ('accuracy',\n",
              "                             [0.004493119910137602,\n",
              "                              0.018534119629317607,\n",
              "                              0.5922493681550126,\n",
              "                              0.6447627071047458,\n",
              "                              0.6498174670036506,\n",
              "                              0.6536085369278293,\n",
              "                              0.6508003369839933,\n",
              "                              0.6588037068239259,\n",
              "                              0.6641392867172142,\n",
              "                              0.6600673967986521,\n",
              "                              0.6534681269306375,\n",
              "                              0.6637180567256389,\n",
              "                              0.6720022465599551,\n",
              "                              0.6797247964055041,\n",
              "                              0.6842179163156417,\n",
              "                              0.6882898062342039,\n",
              "                              0.6920808761583824,\n",
              "                              0.6943274361134513,\n",
              "                              0.698680146026397,\n",
              "                              0.7005054759898904,\n",
              "                              0.702190395956192,\n",
              "                              0.7026116259477675,\n",
              "                              0.7026116259477675,\n",
              "                              0.7034540859309183,\n",
              "                              0.7033136759337265,\n",
              "                              0.7038753159224936,\n",
              "                              0.7049985959000281,\n",
              "                              0.7051390058972199,\n",
              "                              0.7057006458859871,\n",
              "                              0.7054198258916035,\n",
              "                              0.7054198258916035,\n",
              "                              0.7054198258916035,\n",
              "                              0.7055602358887952,\n",
              "                              0.7041561359168773,\n",
              "                              0.7038753159224936,\n",
              "                              0.7044369559112609,\n",
              "                              0.7049985959000281,\n",
              "                              0.7049985959000281,\n",
              "                              0.7049985959000281,\n",
              "                              0.7047177759056444,\n",
              "                              0.7047177759056444,\n",
              "                              0.7047177759056444,\n",
              "                              0.7035944959281101,\n",
              "                              0.7035944959281101,\n",
              "                              0.7033136759337265,\n",
              "                              0.7035944959281101,\n",
              "                              0.7035944959281101,\n",
              "                              0.7042965459140691,\n",
              "                              0.7040157259196855,\n",
              "                              0.7040157259196855,\n",
              "                              0.7040157259196855,\n",
              "                              0.7040157259196855,\n",
              "                              0.7040157259196855,\n",
              "                              0.7040157259196855,\n",
              "                              0.7040157259196855,\n",
              "                              0.7040157259196855,\n",
              "                              0.7027520359449593,\n",
              "                              0.7027520359449593,\n",
              "                              0.7023308059533839,\n",
              "                              0.7023308059533839,\n",
              "                              0.7023308059533839,\n",
              "                              0.7023308059533839,\n",
              "                              0.7024712159505757,\n",
              "                              0.7024712159505757,\n",
              "                              0.7019095759618085,\n",
              "                              0.7019095759618085,\n",
              "                              0.7019095759618085,\n",
              "                              0.702190395956192,\n",
              "                              0.702190395956192,\n",
              "                              0.702190395956192,\n",
              "                              0.702190395956192,\n",
              "                              0.702190395956192,\n",
              "                              0.702190395956192,\n",
              "                              0.702190395956192,\n",
              "                              0.702190395956192,\n",
              "                              0.702190395956192,\n",
              "                              0.702190395956192,\n",
              "                              0.702190395956192,\n",
              "                              0.7037349059253019,\n",
              "                              0.7037349059253019,\n",
              "                              0.7037349059253019,\n",
              "                              0.7037349059253019,\n",
              "                              0.7037349059253019,\n",
              "                              0.7037349059253019,\n",
              "                              0.7037349059253019,\n",
              "                              0.7035944959281101,\n",
              "                              0.7035944959281101,\n",
              "                              0.7035944959281101,\n",
              "                              0.7035944959281101,\n",
              "                              0.7035944959281101,\n",
              "                              0.7035944959281101,\n",
              "                              0.7034540859309183,\n",
              "                              0.7034540859309183,\n",
              "                              0.7034540859309183,\n",
              "                              0.7038753159224936,\n",
              "                              0.7038753159224936,\n",
              "                              0.7040157259196855,\n",
              "                              0.7040157259196855,\n",
              "                              0.7040157259196855,\n",
              "                              0.7040157259196855]),\n",
              "                            ('hits_at_k',\n",
              "                             [0.7798371244032575,\n",
              "                              0.7819432743611345,\n",
              "                              0.7822240943555181,\n",
              "                              0.7822240943555181,\n",
              "                              0.7816624543667509,\n",
              "                              0.7833473743330525,\n",
              "                              0.8160629036787419,\n",
              "                              0.8368435832631284,\n",
              "                              0.843442853131143,\n",
              "                              0.8416175231676495,\n",
              "                              0.8576242628475147,\n",
              "                              0.8682954226340915,\n",
              "                              0.8765796124684078,\n",
              "                              0.8812131423757371,\n",
              "                              0.8838809323223814,\n",
              "                              0.8854254422914911,\n",
              "                              0.8878124122437517,\n",
              "                              0.8868295422634092,\n",
              "                              0.8878124122437517,\n",
              "                              0.888374052232519,\n",
              "                              0.8893569222128616,\n",
              "                              0.8893569222128616,\n",
              "                              0.8899185622016288,\n",
              "                              0.8906206121875877,\n",
              "                              0.8923055321538893,\n",
              "                              0.8935692221286156,\n",
              "                              0.8948329121033417,\n",
              "                              0.8976411120471778,\n",
              "                              0.8983431620331368,\n",
              "                              0.900308901993822,\n",
              "                              0.9021342319573153,\n",
              "                              0.9032575119348497,\n",
              "                              0.904521201909576,\n",
              "                              0.904521201909576,\n",
              "                              0.9039595619208087,\n",
              "                              0.9053636618927268,\n",
              "                              0.904521201909576,\n",
              "                              0.904521201909576,\n",
              "                              0.905223251895535,\n",
              "                              0.9053636618927268,\n",
              "                              0.9053636618927268,\n",
              "                              0.9055040718899185,\n",
              "                              0.9053636618927268,\n",
              "                              0.9053636618927268,\n",
              "                              0.9050828418983432,\n",
              "                              0.9040999719180005,\n",
              "                              0.9036787419264252,\n",
              "                              0.903819151923617,\n",
              "                              0.9046616119067677,\n",
              "                              0.9043807919123842,\n",
              "                              0.9042403819151924,\n",
              "                              0.9039595619208087,\n",
              "                              0.9056444818871103,\n",
              "                              0.9053636618927268,\n",
              "                              0.9056444818871103,\n",
              "                              0.9056444818871103,\n",
              "                              0.9056444818871103,\n",
              "                              0.905223251895535,\n",
              "                              0.9053636618927268,\n",
              "                              0.9033979219320416,\n",
              "                              0.9033979219320416,\n",
              "                              0.9035383319292334,\n",
              "                              0.9048020219039595,\n",
              "                              0.9048020219039595,\n",
              "                              0.9048020219039595,\n",
              "                              0.9048020219039595,\n",
              "                              0.9049424319011513,\n",
              "                              0.9060657118786858,\n",
              "                              0.9060657118786858,\n",
              "                              0.9060657118786858,\n",
              "                              0.9060657118786858,\n",
              "                              0.9060657118786858,\n",
              "                              0.9060657118786858,\n",
              "                              0.9060657118786858,\n",
              "                              0.9060657118786858,\n",
              "                              0.9053636618927268,\n",
              "                              0.9053636618927268,\n",
              "                              0.9053636618927268,\n",
              "                              0.9053636618927268,\n",
              "                              0.9053636618927268,\n",
              "                              0.9057848918843021,\n",
              "                              0.9057848918843021,\n",
              "                              0.9057848918843021,\n",
              "                              0.9057848918843021,\n",
              "                              0.9057848918843021,\n",
              "                              0.9057848918843021,\n",
              "                              0.9057848918843021,\n",
              "                              0.9057848918843021,\n",
              "                              0.9057848918843021,\n",
              "                              0.9057848918843021,\n",
              "                              0.9064869418702611,\n",
              "                              0.9064869418702611,\n",
              "                              0.9071889918562202,\n",
              "                              0.9071889918562202,\n",
              "                              0.9071889918562202,\n",
              "                              0.9071889918562202,\n",
              "                              0.9071889918562202,\n",
              "                              0.9071889918562202,\n",
              "                              0.9070485818590284,\n",
              "                              0.9070485818590284])])),\n",
              "              ('combined',\n",
              "               {'accuracy': [0.004493119910137602,\n",
              "                 0.018534119629317607,\n",
              "                 0.5922493681550126,\n",
              "                 0.6447627071047458,\n",
              "                 0.6498174670036506,\n",
              "                 0.6536085369278293,\n",
              "                 0.6508003369839933,\n",
              "                 0.6588037068239259,\n",
              "                 0.6641392867172142,\n",
              "                 0.6600673967986521,\n",
              "                 0.6534681269306375,\n",
              "                 0.6637180567256389,\n",
              "                 0.6720022465599551,\n",
              "                 0.6797247964055041,\n",
              "                 0.6842179163156417,\n",
              "                 0.6882898062342039,\n",
              "                 0.6920808761583824,\n",
              "                 0.6943274361134513,\n",
              "                 0.698680146026397,\n",
              "                 0.7005054759898904,\n",
              "                 0.702190395956192,\n",
              "                 0.7026116259477675,\n",
              "                 0.7026116259477675,\n",
              "                 0.7034540859309183,\n",
              "                 0.7033136759337265,\n",
              "                 0.7038753159224936,\n",
              "                 0.7049985959000281,\n",
              "                 0.7051390058972199,\n",
              "                 0.7057006458859871,\n",
              "                 0.7054198258916035,\n",
              "                 0.7054198258916035,\n",
              "                 0.7054198258916035,\n",
              "                 0.7055602358887952,\n",
              "                 0.7041561359168773,\n",
              "                 0.7038753159224936,\n",
              "                 0.7044369559112609,\n",
              "                 0.7049985959000281,\n",
              "                 0.7049985959000281,\n",
              "                 0.7049985959000281,\n",
              "                 0.7047177759056444,\n",
              "                 0.7047177759056444,\n",
              "                 0.7047177759056444,\n",
              "                 0.7035944959281101,\n",
              "                 0.7035944959281101,\n",
              "                 0.7033136759337265,\n",
              "                 0.7035944959281101,\n",
              "                 0.7035944959281101,\n",
              "                 0.7042965459140691,\n",
              "                 0.7040157259196855,\n",
              "                 0.7040157259196855,\n",
              "                 0.7040157259196855,\n",
              "                 0.7040157259196855,\n",
              "                 0.7040157259196855,\n",
              "                 0.7040157259196855,\n",
              "                 0.7040157259196855,\n",
              "                 0.7040157259196855,\n",
              "                 0.7027520359449593,\n",
              "                 0.7027520359449593,\n",
              "                 0.7023308059533839,\n",
              "                 0.7023308059533839,\n",
              "                 0.7023308059533839,\n",
              "                 0.7023308059533839,\n",
              "                 0.7024712159505757,\n",
              "                 0.7024712159505757,\n",
              "                 0.7019095759618085,\n",
              "                 0.7019095759618085,\n",
              "                 0.7019095759618085,\n",
              "                 0.702190395956192,\n",
              "                 0.702190395956192,\n",
              "                 0.702190395956192,\n",
              "                 0.702190395956192,\n",
              "                 0.702190395956192,\n",
              "                 0.702190395956192,\n",
              "                 0.702190395956192,\n",
              "                 0.702190395956192,\n",
              "                 0.702190395956192,\n",
              "                 0.702190395956192,\n",
              "                 0.702190395956192,\n",
              "                 0.7037349059253019,\n",
              "                 0.7037349059253019,\n",
              "                 0.7037349059253019,\n",
              "                 0.7037349059253019,\n",
              "                 0.7037349059253019,\n",
              "                 0.7037349059253019,\n",
              "                 0.7037349059253019,\n",
              "                 0.7035944959281101,\n",
              "                 0.7035944959281101,\n",
              "                 0.7035944959281101,\n",
              "                 0.7035944959281101,\n",
              "                 0.7035944959281101,\n",
              "                 0.7035944959281101,\n",
              "                 0.7034540859309183,\n",
              "                 0.7034540859309183,\n",
              "                 0.7034540859309183,\n",
              "                 0.7038753159224936,\n",
              "                 0.7038753159224936,\n",
              "                 0.7040157259196855,\n",
              "                 0.7040157259196855,\n",
              "                 0.7040157259196855,\n",
              "                 0.7040157259196855],\n",
              "                'loss': [14.667233671441704,\n",
              "                 8.388423603660971,\n",
              "                 5.377235209061436,\n",
              "                 4.412309341837736,\n",
              "                 3.5438300917169347,\n",
              "                 2.730825896076994,\n",
              "                 2.1499660634418714,\n",
              "                 1.8047805631873783,\n",
              "                 1.5264882144215601,\n",
              "                 1.3515812960343225,\n",
              "                 1.2732222647320117,\n",
              "                 1.2199064328140905,\n",
              "                 1.1760733330460686,\n",
              "                 1.1385710827924669,\n",
              "                 1.105920953919331,\n",
              "                 1.0773412173666737,\n",
              "                 1.0523343106328487,\n",
              "                 1.0305173510214278,\n",
              "                 1.011555421824403,\n",
              "                 0.9951385009559947,\n",
              "                 0.9809754373517742,\n",
              "                 0.9687963816196321,\n",
              "                 0.9583533902209784,\n",
              "                 0.949420519740151,\n",
              "                 0.9417926688704454,\n",
              "                 0.9352845885853391,\n",
              "                 0.9297305350556732,\n",
              "                 0.9249844431910612,\n",
              "                 0.9209194552928536,\n",
              "                 0.917426989072496,\n",
              "                 0.9144152122011214,\n",
              "                 0.9118071837024855,\n",
              "                 0.9095387950234117,\n",
              "                 0.9075567818062923,\n",
              "                 0.9058171298791103,\n",
              "                 0.9042831748698876,\n",
              "                 0.9029245855968275,\n",
              "                 0.9017161996268851,\n",
              "                 0.9006369798848282,\n",
              "                 0.8996693461974395,\n",
              "                 0.8987986300306955,\n",
              "                 0.898012402820239,\n",
              "                 0.8973002103030497,\n",
              "                 0.8966531408064086,\n",
              "                 0.8960635949305957,\n",
              "                 0.8955251762820776,\n",
              "                 0.8950322340526329,\n",
              "                 0.8945799497900568,\n",
              "                 0.8941640845847512,\n",
              "                 0.8937809962096157,\n",
              "                 0.8934274805760457,\n",
              "                 0.8931006946044168,\n",
              "                 0.892798210857491,\n",
              "                 0.8925177068798704,\n",
              "                 0.8922572351513,\n",
              "                 0.8920150763263397,\n",
              "                 0.8917895924740379,\n",
              "                 0.8915793406297169,\n",
              "                 0.8913831252858934,\n",
              "                 0.8911996855892448,\n",
              "                 0.8910280627770493,\n",
              "                 0.8908672659492868,\n",
              "                 0.8907164038315613,\n",
              "                 0.8905747608333717,\n",
              "                 0.8904415581608649,\n",
              "                 0.89031618199165,\n",
              "                 0.8901980945616081,\n",
              "                 0.8900865502854272,\n",
              "                 0.889981253499966,\n",
              "                 0.8898816964359171,\n",
              "                 0.8897874613084072,\n",
              "                 0.889698088554076,\n",
              "                 0.88961331464708,\n",
              "                 0.8895327839346556,\n",
              "                 0.8894562425321489,\n",
              "                 0.8893833251456068,\n",
              "                 0.8893138646610799,\n",
              "                 0.8892475868402924,\n",
              "                 0.8891842527959963,\n",
              "                 0.8891237489764057,\n",
              "                 0.8890658654178404,\n",
              "                 0.8890103653755391,\n",
              "                 0.8889571524376081,\n",
              "                 0.8889060627038275,\n",
              "                 0.8888569986910607,\n",
              "                 0.8888098329213588,\n",
              "                 0.8887643725709344,\n",
              "                 0.8887205908587058,\n",
              "                 0.8886783699479139,\n",
              "                 0.8886376102129351,\n",
              "                 0.8885982398804705,\n",
              "                 0.8885601925334379,\n",
              "                 0.8885233910423221,\n",
              "                 0.8884876897180392,\n",
              "                 0.8884531667613474,\n",
              "                 0.8884196186360266,\n",
              "                 0.8883870903342937,\n",
              "                 0.8883555165103098,\n",
              "                 0.8883248361032084,\n",
              "                 0.8882949687697451]})]),\n",
              " 'validation': OrderedDict([('dx',\n",
              "               OrderedDict([('loss',\n",
              "                             [15.712794534091291,\n",
              "                              9.349535021288641,\n",
              "                              6.277313750365685,\n",
              "                              5.199100831459308,\n",
              "                              4.215151383959014,\n",
              "                              3.287050095097772,\n",
              "                              2.5968475095156967,\n",
              "                              2.1575849796163626,\n",
              "                              1.7855828342766598,\n",
              "                              1.5313808548039403,\n",
              "                              1.4182334850574363,\n",
              "                              1.355664347780162,\n",
              "                              1.3065908612876103,\n",
              "                              1.2650631953930032,\n",
              "                              1.2291123373755093,\n",
              "                              1.1977222417962963,\n",
              "                              1.1702805716415932,\n",
              "                              1.1463369788794682,\n",
              "                              1.1255086783705086,\n",
              "                              1.1074487587501263,\n",
              "                              1.091835618019104,\n",
              "                              1.07837516686012,\n",
              "                              1.0667994803395764,\n",
              "                              1.0568670157728524,\n",
              "                              1.048359180318898,\n",
              "                              1.0410792067133148,\n",
              "                              1.0348502767497096,\n",
              "                              1.0295157555876107,\n",
              "                              1.0249382319121525,\n",
              "                              1.0209995138234105,\n",
              "                              1.0175991777716011,\n",
              "                              1.0146525399438266,\n",
              "                              1.0120889133420483,\n",
              "                              1.0098493777472397,\n",
              "                              1.0078853327652504,\n",
              "                              1.0061558772777688,\n",
              "                              1.0046274846997754,\n",
              "                              1.003271978476952,\n",
              "                              1.0020658558812634,\n",
              "                              1.0009892459573417,\n",
              "                              1.0000256299972534,\n",
              "                              0.9991609577474923,\n",
              "                              0.998383431599058,\n",
              "                              0.9976825138618206,\n",
              "                              0.9970497139568987,\n",
              "                              0.9964773038337971,\n",
              "                              0.9959589510128416,\n",
              "                              0.9954889067288103,\n",
              "                              0.9950622114641913,\n",
              "                              0.9946743023806605,\n",
              "                              0.9943215189308956,\n",
              "                              0.9940004800928051,\n",
              "                              0.9937081871361568,\n",
              "                              0.9934419105792868,\n",
              "                              0.9931991141417931,\n",
              "                              0.992977748657095,\n",
              "                              0.9927759149978901,\n",
              "                              0.992591825024835,\n",
              "                              0.9924239290171656,\n",
              "                              0.9922707594674209,\n",
              "                              0.9921311325040357,\n",
              "                              0.9920037532674855,\n",
              "                              0.9918875385975016,\n",
              "                              0.9917817156890343,\n",
              "                              0.9916852137138104,\n",
              "                              0.9915974140167236,\n",
              "                              0.9915173300381365,\n",
              "                              0.9914446349801689,\n",
              "                              0.9913784224411537,\n",
              "                              0.9913183019079012,\n",
              "                              0.9912637019979542,\n",
              "                              0.9912142712494423,\n",
              "                              0.9911694485565712,\n",
              "                              0.9911289913900967,\n",
              "                              0.9910922831502454,\n",
              "                              0.991059280675033,\n",
              "                              0.9910295030166363,\n",
              "                              0.9910028700170845,\n",
              "                              0.9909788822305614,\n",
              "                              0.9909575951510462,\n",
              "                              0.9909385360520462,\n",
              "                              0.9909215672262783,\n",
              "                              0.9909066907290754,\n",
              "                              0.9908934338339443,\n",
              "                              0.9908820472914597,\n",
              "                              0.9908720028811487,\n",
              "                              0.9908633725396518,\n",
              "                              0.9908560637770027,\n",
              "                              0.9908498484512855,\n",
              "                              0.9908448087758032,\n",
              "                              0.9908406323400037,\n",
              "                              0.9908374527405048,\n",
              "                              0.9908350541673857,\n",
              "                              0.9908332701387077,\n",
              "                              0.9908322753577397,\n",
              "                              0.9908320492711561,\n",
              "                              0.9908322136977623,\n",
              "                              0.9908329823921467,\n",
              "                              0.9908342135363611,\n",
              "                              0.9908358002531117]),\n",
              "                            ('accuracy',\n",
              "                             [0.005387931034482759,\n",
              "                              0.016163793103448277,\n",
              "                              0.5614224137931034,\n",
              "                              0.6163793103448276,\n",
              "                              0.6228448275862069,\n",
              "                              0.6228448275862069,\n",
              "                              0.6120689655172413,\n",
              "                              0.615301724137931,\n",
              "                              0.6206896551724138,\n",
              "                              0.6174568965517241,\n",
              "                              0.6217672413793104,\n",
              "                              0.625,\n",
              "                              0.634698275862069,\n",
              "                              0.6476293103448276,\n",
              "                              0.6487068965517241,\n",
              "                              0.6519396551724138,\n",
              "                              0.65625,\n",
              "                              0.6584051724137931,\n",
              "                              0.6584051724137931,\n",
              "                              0.6594827586206896,\n",
              "                              0.6594827586206896,\n",
              "                              0.6594827586206896,\n",
              "                              0.6616379310344828,\n",
              "                              0.6648706896551724,\n",
              "                              0.6681034482758621,\n",
              "                              0.6681034482758621,\n",
              "                              0.6691810344827587,\n",
              "                              0.6691810344827587,\n",
              "                              0.6691810344827587,\n",
              "                              0.6691810344827587,\n",
              "                              0.6691810344827587,\n",
              "                              0.6691810344827587,\n",
              "                              0.6702586206896551,\n",
              "                              0.6691810344827587,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6681034482758621,\n",
              "                              0.6681034482758621,\n",
              "                              0.6681034482758621,\n",
              "                              0.6681034482758621,\n",
              "                              0.6681034482758621,\n",
              "                              0.6681034482758621,\n",
              "                              0.6691810344827587,\n",
              "                              0.6691810344827587,\n",
              "                              0.6670258620689655,\n",
              "                              0.6670258620689655,\n",
              "                              0.6670258620689655,\n",
              "                              0.665948275862069,\n",
              "                              0.665948275862069,\n",
              "                              0.665948275862069,\n",
              "                              0.665948275862069,\n",
              "                              0.665948275862069,\n",
              "                              0.665948275862069,\n",
              "                              0.665948275862069,\n",
              "                              0.665948275862069,\n",
              "                              0.665948275862069,\n",
              "                              0.665948275862069,\n",
              "                              0.665948275862069,\n",
              "                              0.6681034482758621,\n",
              "                              0.6681034482758621,\n",
              "                              0.6681034482758621,\n",
              "                              0.6681034482758621,\n",
              "                              0.6681034482758621,\n",
              "                              0.6681034482758621,\n",
              "                              0.6681034482758621,\n",
              "                              0.6681034482758621,\n",
              "                              0.6681034482758621,\n",
              "                              0.6681034482758621,\n",
              "                              0.6681034482758621,\n",
              "                              0.6681034482758621,\n",
              "                              0.6681034482758621,\n",
              "                              0.6681034482758621,\n",
              "                              0.6681034482758621,\n",
              "                              0.6681034482758621,\n",
              "                              0.6691810344827587,\n",
              "                              0.6691810344827587,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551,\n",
              "                              0.6702586206896551]),\n",
              "                            ('hits_at_k',\n",
              "                             [0.7543103448275862,\n",
              "                              0.7543103448275862,\n",
              "                              0.7532327586206896,\n",
              "                              0.7543103448275862,\n",
              "                              0.7543103448275862,\n",
              "                              0.7510775862068966,\n",
              "                              0.7801724137931034,\n",
              "                              0.7952586206896551,\n",
              "                              0.8103448275862069,\n",
              "                              0.8038793103448276,\n",
              "                              0.8297413793103449,\n",
              "                              0.8405172413793104,\n",
              "                              0.8480603448275862,\n",
              "                              0.8545258620689655,\n",
              "                              0.8588362068965517,\n",
              "                              0.8631465517241379,\n",
              "                              0.8631465517241379,\n",
              "                              0.8642241379310345,\n",
              "                              0.865301724137931,\n",
              "                              0.865301724137931,\n",
              "                              0.8642241379310345,\n",
              "                              0.8631465517241379,\n",
              "                              0.8642241379310345,\n",
              "                              0.8642241379310345,\n",
              "                              0.865301724137931,\n",
              "                              0.8674568965517241,\n",
              "                              0.8663793103448276,\n",
              "                              0.8706896551724138,\n",
              "                              0.8706896551724138,\n",
              "                              0.8717672413793104,\n",
              "                              0.8739224137931034,\n",
              "                              0.8793103448275862,\n",
              "                              0.8793103448275862,\n",
              "                              0.8782327586206896,\n",
              "                              0.8793103448275862,\n",
              "                              0.8793103448275862,\n",
              "                              0.8771551724137931,\n",
              "                              0.8782327586206896,\n",
              "                              0.8825431034482759,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8803879310344828,\n",
              "                              0.8803879310344828,\n",
              "                              0.8793103448275862,\n",
              "                              0.8793103448275862,\n",
              "                              0.8771551724137931,\n",
              "                              0.8782327586206896,\n",
              "                              0.8825431034482759,\n",
              "                              0.8814655172413793,\n",
              "                              0.8825431034482759,\n",
              "                              0.8814655172413793,\n",
              "                              0.8825431034482759,\n",
              "                              0.8836206896551724,\n",
              "                              0.8836206896551724,\n",
              "                              0.8836206896551724,\n",
              "                              0.8836206896551724,\n",
              "                              0.8836206896551724,\n",
              "                              0.8836206896551724,\n",
              "                              0.8825431034482759,\n",
              "                              0.8825431034482759,\n",
              "                              0.8825431034482759,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8803879310344828,\n",
              "                              0.8803879310344828,\n",
              "                              0.8803879310344828,\n",
              "                              0.8803879310344828,\n",
              "                              0.8803879310344828,\n",
              "                              0.8803879310344828,\n",
              "                              0.8803879310344828,\n",
              "                              0.8803879310344828,\n",
              "                              0.8803879310344828,\n",
              "                              0.8803879310344828,\n",
              "                              0.8803879310344828,\n",
              "                              0.8803879310344828,\n",
              "                              0.8803879310344828,\n",
              "                              0.8803879310344828,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793,\n",
              "                              0.8814655172413793])])),\n",
              "              ('combined',\n",
              "               {'accuracy': [0.005387931034482759,\n",
              "                 0.016163793103448277,\n",
              "                 0.5614224137931034,\n",
              "                 0.6163793103448276,\n",
              "                 0.6228448275862069,\n",
              "                 0.6228448275862069,\n",
              "                 0.6120689655172413,\n",
              "                 0.615301724137931,\n",
              "                 0.6206896551724138,\n",
              "                 0.6174568965517241,\n",
              "                 0.6217672413793104,\n",
              "                 0.625,\n",
              "                 0.634698275862069,\n",
              "                 0.6476293103448276,\n",
              "                 0.6487068965517241,\n",
              "                 0.6519396551724138,\n",
              "                 0.65625,\n",
              "                 0.6584051724137931,\n",
              "                 0.6584051724137931,\n",
              "                 0.6594827586206896,\n",
              "                 0.6594827586206896,\n",
              "                 0.6594827586206896,\n",
              "                 0.6616379310344828,\n",
              "                 0.6648706896551724,\n",
              "                 0.6681034482758621,\n",
              "                 0.6681034482758621,\n",
              "                 0.6691810344827587,\n",
              "                 0.6691810344827587,\n",
              "                 0.6691810344827587,\n",
              "                 0.6691810344827587,\n",
              "                 0.6691810344827587,\n",
              "                 0.6691810344827587,\n",
              "                 0.6702586206896551,\n",
              "                 0.6691810344827587,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6681034482758621,\n",
              "                 0.6681034482758621,\n",
              "                 0.6681034482758621,\n",
              "                 0.6681034482758621,\n",
              "                 0.6681034482758621,\n",
              "                 0.6681034482758621,\n",
              "                 0.6691810344827587,\n",
              "                 0.6691810344827587,\n",
              "                 0.6670258620689655,\n",
              "                 0.6670258620689655,\n",
              "                 0.6670258620689655,\n",
              "                 0.665948275862069,\n",
              "                 0.665948275862069,\n",
              "                 0.665948275862069,\n",
              "                 0.665948275862069,\n",
              "                 0.665948275862069,\n",
              "                 0.665948275862069,\n",
              "                 0.665948275862069,\n",
              "                 0.665948275862069,\n",
              "                 0.665948275862069,\n",
              "                 0.665948275862069,\n",
              "                 0.665948275862069,\n",
              "                 0.6681034482758621,\n",
              "                 0.6681034482758621,\n",
              "                 0.6681034482758621,\n",
              "                 0.6681034482758621,\n",
              "                 0.6681034482758621,\n",
              "                 0.6681034482758621,\n",
              "                 0.6681034482758621,\n",
              "                 0.6681034482758621,\n",
              "                 0.6681034482758621,\n",
              "                 0.6681034482758621,\n",
              "                 0.6681034482758621,\n",
              "                 0.6681034482758621,\n",
              "                 0.6681034482758621,\n",
              "                 0.6681034482758621,\n",
              "                 0.6681034482758621,\n",
              "                 0.6681034482758621,\n",
              "                 0.6691810344827587,\n",
              "                 0.6691810344827587,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551,\n",
              "                 0.6702586206896551],\n",
              "                'loss': [15.712794534091291,\n",
              "                 9.349535021288641,\n",
              "                 6.277313750365685,\n",
              "                 5.199100831459308,\n",
              "                 4.215151383959014,\n",
              "                 3.287050095097772,\n",
              "                 2.5968475095156967,\n",
              "                 2.1575849796163626,\n",
              "                 1.7855828342766598,\n",
              "                 1.5313808548039403,\n",
              "                 1.4182334850574363,\n",
              "                 1.355664347780162,\n",
              "                 1.3065908612876103,\n",
              "                 1.2650631953930032,\n",
              "                 1.2291123373755093,\n",
              "                 1.1977222417962963,\n",
              "                 1.1702805716415932,\n",
              "                 1.1463369788794682,\n",
              "                 1.1255086783705086,\n",
              "                 1.1074487587501263,\n",
              "                 1.091835618019104,\n",
              "                 1.07837516686012,\n",
              "                 1.0667994803395764,\n",
              "                 1.0568670157728524,\n",
              "                 1.048359180318898,\n",
              "                 1.0410792067133148,\n",
              "                 1.0348502767497096,\n",
              "                 1.0295157555876107,\n",
              "                 1.0249382319121525,\n",
              "                 1.0209995138234105,\n",
              "                 1.0175991777716011,\n",
              "                 1.0146525399438266,\n",
              "                 1.0120889133420483,\n",
              "                 1.0098493777472397,\n",
              "                 1.0078853327652504,\n",
              "                 1.0061558772777688,\n",
              "                 1.0046274846997754,\n",
              "                 1.003271978476952,\n",
              "                 1.0020658558812634,\n",
              "                 1.0009892459573417,\n",
              "                 1.0000256299972534,\n",
              "                 0.9991609577474923,\n",
              "                 0.998383431599058,\n",
              "                 0.9976825138618206,\n",
              "                 0.9970497139568987,\n",
              "                 0.9964773038337971,\n",
              "                 0.9959589510128416,\n",
              "                 0.9954889067288103,\n",
              "                 0.9950622114641913,\n",
              "                 0.9946743023806605,\n",
              "                 0.9943215189308956,\n",
              "                 0.9940004800928051,\n",
              "                 0.9937081871361568,\n",
              "                 0.9934419105792868,\n",
              "                 0.9931991141417931,\n",
              "                 0.992977748657095,\n",
              "                 0.9927759149978901,\n",
              "                 0.992591825024835,\n",
              "                 0.9924239290171656,\n",
              "                 0.9922707594674209,\n",
              "                 0.9921311325040357,\n",
              "                 0.9920037532674855,\n",
              "                 0.9918875385975016,\n",
              "                 0.9917817156890343,\n",
              "                 0.9916852137138104,\n",
              "                 0.9915974140167236,\n",
              "                 0.9915173300381365,\n",
              "                 0.9914446349801689,\n",
              "                 0.9913784224411537,\n",
              "                 0.9913183019079012,\n",
              "                 0.9912637019979542,\n",
              "                 0.9912142712494423,\n",
              "                 0.9911694485565712,\n",
              "                 0.9911289913900967,\n",
              "                 0.9910922831502454,\n",
              "                 0.991059280675033,\n",
              "                 0.9910295030166363,\n",
              "                 0.9910028700170845,\n",
              "                 0.9909788822305614,\n",
              "                 0.9909575951510462,\n",
              "                 0.9909385360520462,\n",
              "                 0.9909215672262783,\n",
              "                 0.9909066907290754,\n",
              "                 0.9908934338339443,\n",
              "                 0.9908820472914597,\n",
              "                 0.9908720028811487,\n",
              "                 0.9908633725396518,\n",
              "                 0.9908560637770027,\n",
              "                 0.9908498484512855,\n",
              "                 0.9908448087758032,\n",
              "                 0.9908406323400037,\n",
              "                 0.9908374527405048,\n",
              "                 0.9908350541673857,\n",
              "                 0.9908332701387077,\n",
              "                 0.9908322753577397,\n",
              "                 0.9908320492711561,\n",
              "                 0.9908322136977623,\n",
              "                 0.9908329823921467,\n",
              "                 0.9908342135363611,\n",
              "                 0.9908358002531117]})])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgq7mxOR8K1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "5e75dac2-6b3b-4ed1-beed-44c5e240a0d5"
      },
      "source": [
        "from ludwig.visualize import *"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_jiCjwb8SUI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "175c19b3-3eba-483a-b03e-0b3316aaa5b7"
      },
      "source": [
        "learning_curves(train_stats, \"dx\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irC2kbvTDU48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqrBYXHv9JUk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "72448d84-d092-43ba-aa29-059c3483574c"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on module ludwig.visualize in ludwig:\n",
            "\n",
            "NAME\n",
            "    ludwig.visualize\n",
            "\n",
            "DESCRIPTION\n",
            "    # coding=utf-8\n",
            "    # Copyright (c) 2019 Uber Technologies, Inc.\n",
            "    #\n",
            "    # Licensed under the Apache License, Version 2.0 (the \"License\");\n",
            "    # you may not use this file except in compliance with the License.\n",
            "    # You may obtain a copy of the License at\n",
            "    #\n",
            "    #     http://www.apache.org/licenses/LICENSE-2.0\n",
            "    #\n",
            "    # Unless required by applicable law or agreed to in writing, software\n",
            "    # distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            "    # See the License for the specific language governing permissions and\n",
            "    # limitations under the License.\n",
            "    # ==============================================================================\n",
            "\n",
            "FUNCTIONS\n",
            "    binary_threshold_vs_metric(probabilities_per_model, ground_truth, metrics, positive_label=1, model_names=None, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Show confidence of the model against metric for the specified output_feature_name.\n",
            "        \n",
            "        For each metric specified in metrics (options are f1, precision, recall,\n",
            "        accuracy), this visualization produces a line chart plotting a threshold\n",
            "        on  the confidence of the model against the metric for the specified\n",
            "        output_feature_name.  If output_feature_name is a category feature, positive_label indicates which is\n",
            "        the class to be considered positive class and all the others will be\n",
            "        considered negative. It needs to be an integer, to figure out the\n",
            "        association between classes and integers check the ground_truth_metadata\n",
            "        JSON file.\n",
            "        \n",
            "        # Inputs\n",
            "        \n",
            "        :param probabilities_per_model: (list) List of model probabilities\n",
            "        :param ground_truth: (list) List of NumPy Arrays containing ground truth data\n",
            "        :param metrics: metrics to dispay (f1, precision, recall,\n",
            "                        accuracy)\n",
            "        :param positive_label: (string) Label of the positive class\n",
            "        :param model_names: (list, default: None) List of the names of the models to use as labels.\n",
            "        :param output_directory: (string, default: None) Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: (string, default: 'pdf') File format of output plots - pdf or png\n",
            "        \n",
            "        # Return\n",
            "        \n",
            "        :return: (None)\n",
            "    \n",
            "    binary_threshold_vs_metric_cli(probabilities, ground_truth, ground_truth_split, output_feature_name, **kwargs)\n",
            "        Load model data from files to be shown by binary_threshold_vs_metric_cli.\n",
            "        \n",
            "        :param probabilities: Path to experiment probabilities file\n",
            "        :param ground_truth: Path to ground truth file\n",
            "        :param ground_truth_split: Type of ground truth split - train, val, test\n",
            "        :param output_feature_name: Name of the output feature to visualize\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    calibration_1_vs_all(probabilities_per_model, ground_truth, top_n_classes, labels_limit, model_names=None, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Show models probability of predictions for the specified output_feature_name.\n",
            "        \n",
            "        For each class or each of the k most frequent classes if top_k is\n",
            "        specified,  it produces two plots computed on the fly from the\n",
            "        probabilities  of predictions for the specified output_feature_name.\n",
            "        \n",
            "        The first plot is a calibration curve that shows the calibration of the\n",
            "        predictions considering the current class to be the true one and all\n",
            "        others  to be a false one, drawing one line for each model (in the\n",
            "        aligned  lists of probabilities and model_names).\n",
            "        \n",
            "        The second plot shows the distributions of the predictions considering\n",
            "        the  current class to be the true one and all others to be a false one,\n",
            "        drawing the distribution for each model (in the aligned lists of\n",
            "        probabilities and model_names).\n",
            "        \n",
            "        # Inputs\n",
            "        \n",
            "        :param probabilities_per_model: (list) List of model probabilities\n",
            "        :param ground_truth: (ndarray) NumPy Array containing ground truth data\n",
            "        :param top_n_classes: (list) List containing the number of classes to plot\n",
            "        :param labels_limit: (int) Maximum numbers of labels.\n",
            "                 If labels in dataset are higher than this number, \"rare\" label\n",
            "        :param model_names: (list, default: None) List of the names of the models to use as labels.\n",
            "        :param output_directory: (string, default: None) Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: (string, default: 'pdf') File format of output plots - pdf or png\n",
            "        \n",
            "        # String\n",
            "        \n",
            "        :return: (None)\n",
            "    \n",
            "    calibration_1_vs_all_cli(probabilities, ground_truth, ground_truth_split, output_feature_name, **kwargs)\n",
            "        Load model data from files to be shown by calibration_1_vs_all_cli.\n",
            "        \n",
            "        :param probabilities: Path to experiment probabilities file\n",
            "        :param ground_truth: Path to ground truth file\n",
            "        :param ground_truth_split: Type of ground truth split - train, val, test\n",
            "        :param output_feature_name: Name of the output feature to visualize\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    calibration_multiclass(probabilities_per_model, ground_truth, labels_limit, model_names=None, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Show models probability of predictions for each class of the the\n",
            "        specified output_feature_name.\n",
            "        \n",
            "        # Inputs\n",
            "        \n",
            "        :param probabilities_per_model: (list) List of model probabilities\n",
            "        :param ground_truth: (ndarray) NumPy Array containing ground truth data\n",
            "        :param labels_limit: (int) Maximum numbers of labels.\n",
            "                 If labels in dataset are higher than this number, \"rare\" label\n",
            "        :param model_names: (list, default: None) List of the names of the models to use as labels.\n",
            "        :param output_directory: (string, default: None) Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: (string, default: 'pdf') File format of output plots - pdf or png\n",
            "        \n",
            "        # Return\n",
            "        \n",
            "        :return: (None)\n",
            "    \n",
            "    calibration_multiclass_cli(probabilities, ground_truth, ground_truth_split, output_feature_name, **kwargs)\n",
            "        Load model data from files to be shown by calibration_multiclass_cli.\n",
            "        \n",
            "        :param probabilities: Path to experiment probabilities file\n",
            "        :param ground_truth: Path to ground truth file\n",
            "        :param ground_truth_split: Type of ground truth split - train, val, test\n",
            "        :param output_feature_name: Name of the output feature to visualize\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    cli(sys_argv)\n",
            "    \n",
            "    compare_classifiers_multiclass_multimetric(test_stats_per_model, metadata, output_feature_name, top_n_classes, model_names=None, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Show the precision, recall and F1 of the model for the specified output_feature_name.\n",
            "        \n",
            "        For each model it produces four plots that show the precision,\n",
            "        recall and F1 of the model on several classes for the specified output_feature_name.\n",
            "        \n",
            "        # Inputs\n",
            "        \n",
            "        :param test_stats_per_model: (list) List containing train statistics per model\n",
            "        :param metadata: (dict) Model's input metadata\n",
            "        :param output_feature_name: (string) Name of the output feature that is predicted and for which is provided ground truth\n",
            "        :param top_n_classes: (list) List containing the number of classes to plot\n",
            "        :param model_names: (list, default: None) List of the names of the models to use as labels.\n",
            "        :param output_directory: (string, default: None) Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: (string, default: 'pdf') File format of output plots - pdf or png\n",
            "        \n",
            "        # Return\n",
            "        :return: (None)\n",
            "    \n",
            "    compare_classifiers_multiclass_multimetric_cli(test_statistics, ground_truth_metadata, **kwargs)\n",
            "        Load model data from files to be shown by compare_classifiers_multiclass\n",
            "        \n",
            "        :param test_statistics: Path to experiment test statistics file\n",
            "        :param ground_truth_metadata: Path to ground truth metadata file\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    compare_classifiers_performance_changing_k(probabilities_per_model, ground_truth, top_k, labels_limit, model_names=None, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Produce lineplot that show Hits@K measure while k goes from 1 to top_k.\n",
            "        \n",
            "        \n",
            "        For each model it produces a line plot that shows the Hits@K measure\n",
            "        (that counts a prediction as correct if the model produces it among the\n",
            "        first k) while changing k from 1 to top_k for the specified output_feature_name.\n",
            "        \n",
            "        # Inputs\n",
            "        \n",
            "        :param probabilities_per_model: (list) List of model probabilities\n",
            "        :param ground_truth: (ndarray) NumPy Array containing ground truth data\n",
            "        :param top_k: (int) Number of elements in the ranklist to consider\n",
            "        :param labels_limit: (int) Maximum numbers of labels.\n",
            "                 If labels in dataset are higher than this number, \"rare\" label\n",
            "        :param model_names: (list, default: None) List of the names of the models to use as labels.\n",
            "        :param output_directory: (string, default: None) Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: (string, default: 'pdf') File format of output plots - pdf or png\n",
            "        \n",
            "        # Return\n",
            "        \n",
            "        :return: (None)\n",
            "    \n",
            "    compare_classifiers_performance_changing_k_cli(probabilities, ground_truth, ground_truth_split, output_feature_name, **kwargs)\n",
            "        Load model data from files to be shown by compare_classifiers_changing_k.\n",
            "        \n",
            "        :param probabilities: Path to experiment probabilities file\n",
            "        :param ground_truth: Path to ground truth file\n",
            "        :param ground_truth_split: Type of ground truth split - train, val, test\n",
            "        :param output_feature_name: Name of the output feature to visualize\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    compare_classifiers_performance_from_pred(predictions_per_model, ground_truth, metadata, output_feature_name, labels_limit, model_names=None, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Produces model comparision barplot visualization from predictions.\n",
            "        \n",
            "        For each model it produces bars in a bar plot, one for each overall metric\n",
            "        computed on the fly from the predictions for the specified output_feature_name.\n",
            "        \n",
            "        # Inputs\n",
            "        \n",
            "        :param predictions_per_model: (list) List containing the model predictions\n",
            "               for the specified output_feature_name\n",
            "        :param ground_truth: (ndarray) NumPy Array containing ground truth data\n",
            "        :param metadata: (dict) Model's input metadata\n",
            "        :param output_feature_name: output_feature_name containing ground truth\n",
            "        :param labels_limit: Maximum numbers of labels.\n",
            "                 If labels in dataset are higher than this number, \"rare\" label\n",
            "        :param model_names: List of the names of the models to use as labels.\n",
            "        :param output_directory: Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: File format of output plots - pdf or png\n",
            "        \n",
            "        # Return\n",
            "        \n",
            "        :return: (None)\n",
            "    \n",
            "    compare_classifiers_performance_from_pred_cli(predictions, ground_truth, ground_truth_metadata, ground_truth_split, output_feature_name, **kwargs)\n",
            "        Load model data from files to be shown by compare_classifiers_from_pred\n",
            "        \n",
            "        :param predictions: Path to experiment predictions file\n",
            "        :param ground_truth: Path to ground truth file\n",
            "        :param ground_truth_metadata: Path to ground truth metadata file\n",
            "        :param ground_truth_split: Type of ground truth split - train, val, test\n",
            "        :param output_feature_name: Name of the output feature to visualize\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    compare_classifiers_performance_from_prob(probabilities_per_model, ground_truth, top_n_classes, labels_limit, model_names=None, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Produces model comparision barplot visualization from probabilities.\n",
            "        \n",
            "        For each model it produces bars in a bar plot, one for each overall metric\n",
            "        computed on the fly from the probabilities of predictions for the specified\n",
            "        output_feature_name.\n",
            "        \n",
            "        # Inputs\n",
            "        \n",
            "        :param probabilities_per_model: (list) List of model probabilities\n",
            "        :param ground_truth: (ndarray) NumPy Array containing ground truth data\n",
            "        :param top_n_classes: (list) List containing the number of classes to plot\n",
            "        :param labels_limit: (int) Maximum numbers of labels.\n",
            "                 If labels in dataset are higher than this number, \"rare\" label\n",
            "        :param model_names: (list, default: None) List of the names of the models to use as labels.\n",
            "        :param output_directory: (string, default: None) Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: (string, default: 'pdf') File format of output plots - pdf or png\n",
            "        \n",
            "        # Return\n",
            "        \n",
            "        :return: (None)\n",
            "    \n",
            "    compare_classifiers_performance_from_prob_cli(probabilities, ground_truth, ground_truth_split, output_feature_name, **kwargs)\n",
            "        Load model data from files to be shown by compare_classifiers_from_prob.\n",
            "        \n",
            "        :param probabilities: Path to experiment probabilities file\n",
            "        :param ground_truth: Path to ground truth file\n",
            "        :param ground_truth_split: Type of ground truth split - train, val, test\n",
            "        :param output_feature_name: Name of the output feature to visualize\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    compare_classifiers_performance_subset(probabilities_per_model, ground_truth, top_n_classes, labels_limit, subset, model_names=None, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Produces model comparision barplot visualization from train subset.\n",
            "        \n",
            "        For each model  it produces bars in a bar plot, one for each overall metric\n",
            "         computed on the fly from the probabilities predictions for the\n",
            "         specified output_feature_name, considering only a subset of the full training set.\n",
            "         The way the subset is obtained is using the top_n_classes and\n",
            "         subset parameters.\n",
            "        \n",
            "         # Inputs\n",
            "        \n",
            "        :param probabilities_per_model: (list) List of model probabilities\n",
            "        :param ground_truth: (ndarray) NumPy Array containing ground truth data\n",
            "        :param top_n_classes: (list) List containing the number of classes to plot\n",
            "        :param labels_limit: (int) Maximum numbers of labels.\n",
            "        :param subset: () Type of the subset filtering\n",
            "        :param model_names: (list, default: None) List of the names of the models to use as labels.\n",
            "        :param output_directory: (string, default: None) Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: (string, default: 'pdf') File format of output plots - pdf or png\n",
            "        \n",
            "        # Return\n",
            "        \n",
            "        :return: (None)\n",
            "    \n",
            "    compare_classifiers_performance_subset_cli(probabilities, ground_truth, ground_truth_split, output_feature_name, **kwargs)\n",
            "        Load model data from files to be shown by compare_classifiers_subset.\n",
            "        \n",
            "        :param probabilities: Path to experiment probabilities file\n",
            "        :param ground_truth: Path to ground truth file\n",
            "        :param ground_truth_split: Type of ground truth split - train, val, test\n",
            "        :param output_feature_name: Name of the output feature to visualize\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    compare_classifiers_predictions(predictions_per_model, ground_truth, labels_limit, model_names=None, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Show two models comparision of their output_feature_name predictions.\n",
            "        \n",
            "        # Inputs\n",
            "        \n",
            "        :param predictions_per_model: (list) List containing the model predictions\n",
            "        :param ground_truth: (ndarray) NumPy Array containing ground truth data\n",
            "        :param labels_limit: (int) Maximum numbers of labels.\n",
            "                 If labels in dataset are higher than this number, \"rare\" label\n",
            "        :param model_names: (list, default: None) List of the names of the models to use as labels.\n",
            "        :param output_directory: (string, default: None) Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: (string, default: 'pdf') File format of output plots - pdf or png\n",
            "        \n",
            "        # Return\n",
            "        \n",
            "        :return: (None)\n",
            "    \n",
            "    compare_classifiers_predictions_cli(predictions, ground_truth, ground_truth_split, output_feature_name, **kwargs)\n",
            "        Load model data from files to be shown by compare_classifiers_predictions\n",
            "        \n",
            "        :param predictions: Path to experiment predictions file\n",
            "        :param ground_truth: Path to ground truth file\n",
            "        :param ground_truth_split: Type of ground truth split - train, val, test\n",
            "        :param output_feature_name: Name of the output feature to visualize\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    compare_classifiers_predictions_distribution(predictions_per_model, ground_truth, labels_limit, model_names=None, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Show comparision of models predictions distribution for 10 output_feature_name classes\n",
            "        \n",
            "        This visualization produces a radar plot comparing the distributions of\n",
            "        predictions of the models for the first 10 classes of the specified output_feature_name.\n",
            "        \n",
            "        # Inputs\n",
            "        \n",
            "        :param predictions_per_model: (list) List containing the model predictions\n",
            "        :param ground_truth: (ndarray) NumPy Array containing ground truth data\n",
            "        :param labels_limit: (int) Maximum numbers of labels.\n",
            "                 If labels in dataset are higher than this number, \"rare\" label\n",
            "        :param model_names: (list, default: None) List of the names of the models to use as labels.\n",
            "        :param output_directory: (string, default: None) Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: (string, default: 'pdf') File format of output plots - pdf or png\n",
            "        \n",
            "        # Return\n",
            "        \n",
            "        :return: (None)\n",
            "    \n",
            "    compare_classifiers_predictions_distribution_cli(predictions, ground_truth, ground_truth_split, output_feature_name, **kwargs)\n",
            "        Load model data from files to be shown by\n",
            "        compare_predictions_distribution\n",
            "        \n",
            "        :param predictions: Path to experiment predictions file\n",
            "        :param ground_truth: Path to ground truth file\n",
            "        :param ground_truth_split: Type of ground truth split - train, val, test\n",
            "        :param output_feature_name: Name of the output feature to visualize\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    compare_performance(test_stats_per_model, output_feature_name, model_names=None, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Produces model comparision barplot visualization for each overall metric\n",
            "        \n",
            "        \n",
            "        For each model (in the aligned lists of test_statistics and model_names)\n",
            "        it produces bars in a bar plot, one for each overall metric available\n",
            "        in the test_statistics file for the specified output_feature_name.\n",
            "        \n",
            "        # Inputs\n",
            "        \n",
            "        :param test_stats_per_model: (list) List containing train statistics per model\n",
            "        :param output_feature_name: (string) Name of the output feature that is predicted and for which is provided ground truth\n",
            "        :param model_names: (list, default: None) List of the names of the models to use as labels.\n",
            "        :param output_directory: (string, default: None) Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: (string, default: 'pdf') File format of output plots - pdf or png\n",
            "        \n",
            "        # Return\n",
            "        \n",
            "        :return: (None)\n",
            "    \n",
            "    compare_performance_cli(test_statistics, **kwargs)\n",
            "        Load model data from files to be shown by compare_performance.\n",
            "        \n",
            "        :param test_statistics: Path to experiment test statistics file\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    confidence_thresholding(probabilities_per_model, ground_truth, labels_limit, model_names=None, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Show models accuracy and data coverage while increasing treshold\n",
            "        \n",
            "        For each model it produces a pair of lines indicating the accuracy of\n",
            "        the model and the data coverage while increasing a threshold (x axis) on\n",
            "        the probabilities of predictions for the specified output_feature_name.\n",
            "        \n",
            "        # Inputs\n",
            "        \n",
            "        :param probabilities_per_model: (list) List of model probabilities\n",
            "        :param ground_truth: (ndarray) NumPy Array containing ground truth data\n",
            "        :param labels_limit: (int) Maximum numbers of labels.\n",
            "                 If labels in dataset are higher than this number, \"rare\" label\n",
            "        :param model_names: (list, default: None) List of the names of the models to use as labels.\n",
            "        :param output_directory: (sting) Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: (string, default: 'pdf') File format of output plots - pdf or png\n",
            "        \n",
            "        # Return\n",
            "        \n",
            "        :return: (None)\n",
            "    \n",
            "    confidence_thresholding_2thresholds_2d(probabilities_per_model, ground_truths, threshold_output_feature_names, labels_limit, model_names=None, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Show confidence trethreshold data vs accuracy for two output_feature_name thresholds\n",
            "        \n",
            "        The first plot shows several semi transparent lines. They summarize the\n",
            "        3d surfaces displayed by confidence_thresholding_2thresholds_3d that have\n",
            "        thresholds on the confidence of the predictions of the two\n",
            "        threshold_output_feature_names  as x and y axes and either the data coverage percentage or\n",
            "        the accuracy as z axis. Each line represents a slice of the data\n",
            "        coverage  surface projected onto the accuracy surface.\n",
            "        \n",
            "        # Inputs\n",
            "        \n",
            "        :param probabilities_per_model: (list) List of model probabilities\n",
            "        :param ground_truths: (list) List of NumPy Arrays containing ground truth data\n",
            "        :param threshold_output_feature_names: (list) List of output_feature_names for 2d threshold\n",
            "        :param labels_limit: (int) Maximum numbers of labels.\n",
            "                 If labels in dataset are higher than this number, \"rare\" label\n",
            "        :param model_names: (string) Name of the model to use as label.\n",
            "        :param output_directory: (string, default: None) Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: (string, default: 'pdf') File format of output plots - pdf or png\n",
            "        \n",
            "        # Return\n",
            "        \n",
            "        :return: (None)\n",
            "    \n",
            "    confidence_thresholding_2thresholds_2d_cli(probabilities, ground_truth, ground_truth_split, threshold_output_feature_names, **kwargs)\n",
            "        Load model data from files to be shown by\n",
            "        confidence_thresholding_2thresholds_2d_cli\n",
            "        \n",
            "        :param probabilities: Path to experiment probabilities file\n",
            "        :param ground_truth: Path to ground truth file\n",
            "        :param ground_truth_split: Type of ground truth split - train, val, test\n",
            "        :param threshold_output_feature_names: Name of the output feature to visualizes\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    confidence_thresholding_2thresholds_3d(probabilities_per_model, ground_truths, threshold_output_feature_names, labels_limit, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Show 3d confidence trethreshold data vs accuracy for two output_feature_name thresholds\n",
            "        \n",
            "        The plot shows the 3d surfaces displayed by\n",
            "        confidence_thresholding_2thresholds_3d that have thresholds on the\n",
            "        confidence of the predictions of the two threshold_output_feature_names as x and y axes\n",
            "        and either the data coverage percentage or the accuracy as z axis.\n",
            "        \n",
            "        # Inputs\n",
            "        \n",
            "        :param probabilities_per_model: (list) List of model probabilities\n",
            "        :param ground_truths: (list) List of NumPy Arrays containing ground truth data\n",
            "        :param threshold_output_feature_names: (list) List of output_feature_names for 2d threshold\n",
            "        :param labels_limit: (int) Maximum numbers of labels.\n",
            "                 If labels in dataset are higher than this number, \"rare\" label\n",
            "        :param output_directory: (string, default: None) Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: (string, default: 'pdf') File format of output plots - pdf or png\n",
            "        \n",
            "        # Return\n",
            "        \n",
            "        :return: (None)\n",
            "    \n",
            "    confidence_thresholding_2thresholds_3d_cli(probabilities, ground_truth, ground_truth_split, threshold_output_feature_names, **kwargs)\n",
            "        Load model data from files to be shown by\n",
            "        confidence_thresholding_2thresholds_3d_cli\n",
            "        \n",
            "        :param probabilities: Path to experiment probabilities file\n",
            "        :param ground_truth: Path to ground truth file\n",
            "        :param ground_truth_split: Type of ground truth split - train, val, test\n",
            "        :param threshold_output_feature_names: Names of the output features to visualize\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    confidence_thresholding_cli(probabilities, ground_truth, ground_truth_split, output_feature_name, **kwargs)\n",
            "        Load model data from files to be shown by confidence_thresholding.\n",
            "        \n",
            "        :param probabilities: Path to experiment probabilities file\n",
            "        :param ground_truth: Path to ground truth file\n",
            "        :param ground_truth_split: Type of ground truth split - train, val, test\n",
            "        :param output_feature_name: Name of the output feature to visualize\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    confidence_thresholding_data_vs_acc(probabilities_per_model, ground_truth, labels_limit, model_names=None, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Show models comparision of confidence treshold data vs accuracy.\n",
            "        \n",
            "        For each model it produces a line indicating the accuracy of the model\n",
            "        and the data coverage while increasing a threshold on the probabilities\n",
            "        of predictions for the specified output_feature_name. The difference with\n",
            "        confidence_thresholding is that it uses two axes instead of three,\n",
            "        not visualizing the threshold and having coverage as x axis instead of\n",
            "        the threshold.\n",
            "        \n",
            "        # Inputs\n",
            "        \n",
            "        :param probabilities_per_model: (list) List of model probabilities\n",
            "        :param ground_truth: (ndarray) NumPy Array containing ground truth data\n",
            "        :param labels_limit:(int) Maximum numbers of labels.\n",
            "                 If labels in dataset are higher than this number, \"rare\" label\n",
            "        :param model_names: (list, default: None) List of the names of the models to use as labels.\n",
            "        :param output_directory: (string, default: None) Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: (string, default: 'pdf') File format of output plots - pdf or png\n",
            "        \n",
            "        # Return\n",
            "        :return: (None)\n",
            "    \n",
            "    confidence_thresholding_data_vs_acc_cli(probabilities, ground_truth, ground_truth_split, output_feature_name, **kwargs)\n",
            "        Load model data from files to be shown by\n",
            "        confidence_thresholding_data_vs_acc_cli.\n",
            "        \n",
            "        :param probabilities: Path to experiment probabilities file\n",
            "        :param ground_truth: Path to ground truth file\n",
            "        :param ground_truth_split: Type of ground truth split - train, val, test\n",
            "        :param output_feature_name: Name of the output feature to visualize\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    confidence_thresholding_data_vs_acc_subset(probabilities_per_model, ground_truth, top_n_classes, labels_limit, subset, model_names=None, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Show models comparision of confidence treshold data vs accuracy on a\n",
            "        subset of data.\n",
            "        \n",
            "        For each model it produces a line indicating the accuracy of the model\n",
            "        and the data coverage while increasing a threshold on the probabilities\n",
            "        of predictions for the specified output_feature_name, considering only a subset of the\n",
            "        full training set. The way the subset is obtained is using the top_n_classes\n",
            "        and subset parameters.\n",
            "         The difference with confidence_thresholding is that it uses two axes\n",
            "         instead of three, not visualizing the threshold and having coverage as\n",
            "         x axis instead of the threshold.\n",
            "        \n",
            "        If the values of subset is ground_truth, then only datapoints where the\n",
            "        ground truth class is within the top n most frequent ones will be\n",
            "        considered  as test set, and the percentage of datapoints that have been\n",
            "        kept  from the original set will be displayed. If the values of subset is\n",
            "         predictions, then only datapoints where the the model predicts a class\n",
            "         that is within the top n most frequent ones will be considered as test set,\n",
            "         and the percentage of datapoints that have been kept from the original set\n",
            "         will be displayed for each model.\n",
            "        \n",
            "        # Inputs\n",
            "        \n",
            "        :param probabilities_per_model: (list) List of model probabilities\n",
            "        :param ground_truth: (ndarray) NumPy Array containing ground truth data\n",
            "        :param top_n_classes: (list) List containing the number of classes to plot\n",
            "        :param labels_limit: (int) Maximum numbers of labels.\n",
            "        :param subset: (string) Type of the subset filtering\n",
            "        :param model_names: (list, default: None) List of the names of the models to use as labels.\n",
            "        :param output_directory: (string, default: None) Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: (string, default: 'pdf') File format of output plots - pdf or png\n",
            "        \n",
            "        # Return\n",
            "        \n",
            "        :return: (None)\n",
            "    \n",
            "    confidence_thresholding_data_vs_acc_subset_cli(probabilities, ground_truth, ground_truth_split, output_feature_name, **kwargs)\n",
            "        Load model data from files to be shown by\n",
            "        confidence_thresholding_data_vs_acc_subset.\n",
            "        \n",
            "        :param probabilities: Path to experiment probabilities file\n",
            "        :param ground_truth: Path to ground truth file\n",
            "        :param ground_truth_split: Type of ground truth split - train, val, test\n",
            "        :param output_feature_name: Name of the output feature to visualize\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    confidence_thresholding_data_vs_acc_subset_per_class(probabilities_per_model, ground_truth, metadata, output_feature_name, top_n_classes, labels_limit, subset, model_names=None, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Show models comparision of confidence treshold data vs accuracy on a\n",
            "        subset of data per class in top n classes.\n",
            "        \n",
            "        For each model (in the aligned lists of probabilities and model_names)\n",
            "        it produces a line indicating the accuracy of the model and the data\n",
            "        coverage while increasing a threshold on the probabilities of\n",
            "        predictions for the specified output_feature_name, considering only a subset of the\n",
            "        full training set. The way the subset is obtained is using the\n",
            "        top_n_classes  and subset parameters.  The difference with\n",
            "        confidence_thresholding is that it uses two axes instead of three,\n",
            "        not visualizing the threshold and having coverage as x axis instead of\n",
            "        the  threshold.\n",
            "        \n",
            "        If the values of subset is ground_truth, then only datapoints where the\n",
            "        ground truth class is within the top n most frequent ones will be\n",
            "        considered  as test set, and the percentage of datapoints that have been\n",
            "        kept from the original set will be displayed. If the values of subset is\n",
            "        predictions, then only datapoints where the the model predicts a class that\n",
            "        is within the top n most frequent ones will be considered as test set, and\n",
            "        the percentage of datapoints that have been kept from the original set will\n",
            "        be displayed for each model.\n",
            "        \n",
            "        The difference with confidence_thresholding_data_vs_acc_subset is that it\n",
            "        produces one plot per class within the top_n_classes.\n",
            "        \n",
            "        # Inputs\n",
            "        \n",
            "        :param probabilities_per_model: (list) List of model probabilities\n",
            "        :param ground_truth: (ndarray) NumPy Array containing ground truth data\n",
            "        :param metadata: (dict) Model's input metadata\n",
            "        :param top_n_classes: (list) List containing the number of classes to plot\n",
            "        :param labels_limit: (int) Maximum numbers of labels.\n",
            "        :param subset: (string) Type of the subset filtering\n",
            "        :param model_names: (list, default: None) List of the names of the models to use as labels.\n",
            "        :param output_directory: (string, default: None) Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: (string, default: 'pdf') File format of output plots - pdf or png\n",
            "        \n",
            "        # Return\n",
            "        :return: (None)\n",
            "    \n",
            "    confidence_thresholding_data_vs_acc_subset_per_class_cli(probabilities, ground_truth, ground_truth_metadata, ground_truth_split, output_feature_name, **kwargs)\n",
            "        Load model data from files to be shown by compare_classifiers_multiclass\n",
            "        \n",
            "        :param probabilities: Path to experiment probabilities file\n",
            "        :param ground_truth: Path to ground truth file\n",
            "        :param ground_truth_metadata: Path to ground truth metadata file\n",
            "        :param ground_truth_split: Type of ground truth split - train, val, test\n",
            "        :param output_feature_name: Name of the output feature to visualize\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    confusion_matrix(test_stats_per_model, metadata, output_feature_name, top_n_classes, normalize, model_names=None, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Show confision matrix in the models predictions for each output_feature_name.\n",
            "        \n",
            "        For each model (in the aligned lists of test_statistics and model_names)\n",
            "        it  produces a heatmap of the confusion matrix in the predictions for\n",
            "        each  output_feature_name that has a confusion matrix in test_statistics. The value of\n",
            "        top_n_classes limits the heatmap to the n most frequent classes.\n",
            "        \n",
            "        # Inputs\n",
            "        \n",
            "        :param test_stats_per_model: (string) List containing train statistics per model\n",
            "        :param metadata: (dict) Model's input metadata\n",
            "        :param output_feature_name: (string) Name of the output feature that is predicted and for which is provided ground truth\n",
            "        :param top_n_classes: (list) List containing the number of classes to plot\n",
            "        :param normalize: (bool) Flag to normalize rows in confusion matrix\n",
            "        :param model_names: (list, default: None) List of the names of the models to use as labels.\n",
            "        :param output_directory: (string, default: None) Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: (string, default: 'pdf') File format of output plots - pdf or png\n",
            "        \n",
            "        # Return\n",
            "        \n",
            "        :return: (None)\n",
            "    \n",
            "    confusion_matrix_cli(test_statistics, ground_truth_metadata, **kwargs)\n",
            "        Load model data from files to be shown by confusion_matrix.\n",
            "        \n",
            "        :param test_statistics: Path to experiment test statistics file\n",
            "        :param ground_truth_metadata: Path to ground truth metadata file\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    convert_to_list(item)\n",
            "        If item is not list class instance or None put inside a list.\n",
            "        \n",
            "        :param item: object to be checked and converted\n",
            "        :return: original item if it is a list instance or list containing the item.\n",
            "    \n",
            "    frequency_vs_f1(test_stats_per_model, metadata, output_feature_name, top_n_classes, model_names=None, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Show prediction statistics for the specified output_feature_name for each model.\n",
            "        \n",
            "        For each model (in the aligned lists of test_statistics and model_names),\n",
            "        produces two plots statistics of predictions for the specified output_feature_name.\n",
            "        \n",
            "        The first plot is a line plot with one x axis representing the different\n",
            "        classes and two vertical axes colored in orange and blue respectively.\n",
            "        The orange one is the frequency of the class and an orange line is plotted\n",
            "        to show the trend. The blue one is the F1 score for that class and a blue\n",
            "        line is plotted to show the trend. The classes on the x axis are sorted by\n",
            "        f1 score.\n",
            "        The second plot has the same structure of the first one,\n",
            "         but the axes are flipped and the classes on the x axis are sorted by\n",
            "         frequency.\n",
            "        \n",
            "        # Inputs\n",
            "        \n",
            "        :param test_stats_per_model: (list) List containing train statistics per model\n",
            "        :param metadata: (dict) Model's input metadata\n",
            "        :param output_feature_name: (string) Name of the output feature that is predicted and for which is provided ground truth\n",
            "        :param top_n_classes: (list) List containing the number of classes to plot\n",
            "        :param model_names: (list, default: None) List of the names of the models to use as labels.\n",
            "        :param output_directory: (string, default: None) Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: (string, default: 'pdf') File format of output plots - pdf or png\n",
            "        \n",
            "        # Return\n",
            "        \n",
            "        :return: (None)\n",
            "    \n",
            "    frequency_vs_f1_cli(test_statistics, ground_truth_metadata, **kwargs)\n",
            "        Load model data from files to be shown by frequency_vs_f1.\n",
            "        \n",
            "        :param test_statistics: Path to experiment test statistics file\n",
            "        :param ground_truth_metadata: Path to ground truth metadata file\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    generate_filename_template_path(output_dir, filename_template)\n",
            "        Ensure path to template file can be constructed given an output dir.\n",
            "        \n",
            "        Create output directory if yet does exist.\n",
            "        :param output_dir: Directory that will contain the filename_template file\n",
            "        :param filename_template: name of the file template to be appended to the\n",
            "                filename template path\n",
            "        :return: path to filename template inside the output dir or None if the\n",
            "                 output dir is None\n",
            "    \n",
            "    learning_curves(train_stats_per_model, output_feature_name, model_names=None, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Show how model measures change over training and validation data epochs.\n",
            "        \n",
            "        For each model and for each output feature and measure of the model,\n",
            "        it produces a line plot showing how that measure changed over the course\n",
            "        of the epochs of training on the training and validation sets.\n",
            "        \n",
            "        # Inputs\n",
            "        \n",
            "        :param train_stats_per_model: (list) List containing train statistics per model\n",
            "        :param output_feature_name: (string) Name of the output feature that is predicted\n",
            "               and for which is provided ground truth\n",
            "        :param model_names: (list, default: None) List of the names of the models to use as labels.\n",
            "        :param output_directory: (string, default: None) Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: (string, default: 'pdf') File format of output plots - pdf or png\n",
            "        \n",
            "        # Return\n",
            "        :return: (None)\n",
            "    \n",
            "    learning_curves_cli(training_statistics, **kwargs)\n",
            "        Load model data from files to be shown by learning_curves.\n",
            "        \n",
            "        :param training_statistics: Path to experiment training statistics file\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    load_data_for_viz(load_type, model_file_statistics, **kwargs)\n",
            "        Load model file data in to list of .\n",
            "        \n",
            "        :param load_type: type of the data loader to be used.\n",
            "        :param model_file_statistics: JSON file or list of json files containing any\n",
            "               model experiment stats.\n",
            "        :return List of training statistics loaded as json objects.\n",
            "    \n",
            "    roc_curves(probabilities_per_model, ground_truth, positive_label=1, model_names=None, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Show the roc curves for the specified models output output_feature_name.\n",
            "        \n",
            "        This visualization produces a line chart plotting the roc curves for the\n",
            "        specified output_feature_name. If output_feature_name is a category feature, positive_label indicates\n",
            "        which is the class to be considered positive class and all the others will\n",
            "        be considered negative. It needs to be an integer, to figure out the\n",
            "        association between classes and integers check the ground_truth_metadata\n",
            "        JSON file.\n",
            "        \n",
            "        # Inputs\n",
            "        \n",
            "        :param probabilities_per_model: (list) List of model probabilities\n",
            "        :param ground_truth: (list) List of NumPy Arrays containing ground truth data\n",
            "        :param positive_label: (string) Label of the positive class\n",
            "        :param model_names: (list, default: None) List of the names of the models to use as labels.\n",
            "        :param output_directory: (string, default: None) Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: (string, default: 'pdf') File format of output plots - pdf or png\n",
            "        \n",
            "        # Return\n",
            "        \n",
            "        :return: (None)\n",
            "    \n",
            "    roc_curves_cli(probabilities, ground_truth, ground_truth_split, output_feature_name, **kwargs)\n",
            "        Load model data from files to be shown by roc_curves_cli.\n",
            "        \n",
            "        :param probabilities: Path to experiment probabilities file\n",
            "        :param ground_truth: Path to ground truth file\n",
            "        :param ground_truth_split: Type of ground truth split - train, val, test\n",
            "        :param output_feature_name: Name of the output feature to visualize\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    roc_curves_from_test_statistics(test_stats_per_model, output_feature_name, model_names=None, output_directory=None, file_format='pdf', **kwargs)\n",
            "        Show the roc curves for the specified models output binary output_feature_name.\n",
            "        \n",
            "        This visualization uses the output_feature_name, test_statistics and model_names\n",
            "        parameters. output_feature_name needs to be binary feature. This visualization produces a\n",
            "        line chart plotting the roc curves for the specified output_feature_name.\n",
            "        \n",
            "        # Inputs\n",
            "        \n",
            "        :param test_stats_per_model: (list) List containing train statistics per model\n",
            "        :param output_feature_name: (string) Name of the output feature that is predicted and for which is provided ground truth\n",
            "        :param model_names: (list, default: None) List of the names of the models to use as labels.\n",
            "        :param output_directory: (string, default: None) Directory where to save plots.\n",
            "                 If not specified, plots will be displayed in a window\n",
            "        :param file_format: (string, default: 'pdf') File format of output plots - pdf or png\n",
            "        \n",
            "        # Return\n",
            "        \n",
            "        :return: (None)\n",
            "    \n",
            "    roc_curves_from_test_statistics_cli(test_statistics, **kwargs)\n",
            "        Load model data from files to be shown by\n",
            "        roc_curves_from_test_statistics_cli.\n",
            "        \n",
            "        :param test_statistics: Path to experiment test statistics file\n",
            "        :param kwargs: model configuration arguments\n",
            "        :return None:\n",
            "    \n",
            "    validate_conf_treshholds_and_probabilities_2d_3d(probabilities, treshhold_output_feature_names)\n",
            "        Ensure probabilities and treshhold output_feature_names arrays have two members each.\n",
            "        \n",
            "        :param probabilities: List of probabilities per model\n",
            "        :param threshhold_output_feature_names: List of threshhold output_feature_names per model\n",
            "        :raise: RuntimeError\n",
            "\n",
            "DATA\n",
            "    ABSOLUTE_ERROR = 'absolute_error'\n",
            "    ACCURACY = 'accuracy'\n",
            "    APPEND = 'append'\n",
            "    AUDIO = 'audio'\n",
            "    AVG_EXP = 'avg_exp'\n",
            "    BACKFILL = 'backfill'\n",
            "    BAG = 'bag'\n",
            "    BINARY = 'binary'\n",
            "    CATEGORY = 'category'\n",
            "    CORRECT_LAST_PREDICTIONS = 'correct_last_predictions'\n",
            "    CORRECT_OVERALL_PREDICTIONS = 'correct_overall_predictions'\n",
            "    CORRECT_PREDICTIONS = 'correct_predictions'\n",
            "    CORRECT_ROWWISE_PREDICTIONS = 'correct_rowwise_predictions'\n",
            "    CROP_OR_PAD = 'crop_or_pad'\n",
            "    DATE = 'date'\n",
            "    EDIT_DISTANCE = 'edit_distance'\n",
            "    ERROR = 'error'\n",
            "    EVAL_LOSS = 'eval_loss'\n",
            "    FILL_WITH_CONST = 'fill_with_const'\n",
            "    FILL_WITH_MEAN = 'fill_with_mean'\n",
            "    FILL_WITH_MODE = 'fill_with_mode'\n",
            "    FULL = 'full'\n",
            "    H3 = 'h3'\n",
            "    HEIGHT = 'height'\n",
            "    HITS_AT_K = 'hits_at_k'\n",
            "    IMAGE = 'image'\n",
            "    INTERPOLATE = 'interpolate'\n",
            "    JACCARD = 'jaccard'\n",
            "    LAST_ACCURACY = 'last_accuracy'\n",
            "    LAST_PREDICTIONS = 'last_predictions'\n",
            "    LAST_PROBABILTIES = 'last_probabilities'\n",
            "    LENGTHS = 'lengths'\n",
            "    LOSS = 'loss'\n",
            "    MEAN_ABSOLUTE_ERROR = 'mean_absolute_error'\n",
            "    MEAN_HITS_AT_K = 'mean_hits_at_k'\n",
            "    MEAN_SQUARED_ERROR = 'mean_squared_error'\n",
            "    MEASURE = 'measure'\n",
            "    NUMERICAL = 'numerical'\n",
            "    NUM_CHANNELS = 'num_channels'\n",
            "    PERPLEXITY = 'perplexity'\n",
            "    PREDICTION = 'prediction'\n",
            "    PREDICTIONS = 'predictions'\n",
            "    PROBABILITIES = 'probabilities'\n",
            "    PROBABILITY = 'probability'\n",
            "    R2 = 'r2'\n",
            "    ROWWISE_ACCURACY = 'rowwise_accuracy'\n",
            "    SAMPLED_SOFTMAX_CROSS_ENTROPY = 'sampled_softmax_cross_entropy'\n",
            "    SEQUENCE = 'sequence'\n",
            "    SEQ_SUM = 'seq_sum'\n",
            "    SET = 'set'\n",
            "    SOFTMAX_CROSS_ENTROPY = 'softmax_cross_entropy'\n",
            "    SPLIT = 'split'\n",
            "    SQUARED_ERROR = 'squared_error'\n",
            "    SUM = 'sum'\n",
            "    TEST = 'test'\n",
            "    TEXT = 'text'\n",
            "    TIMESERIES = 'timeseries'\n",
            "    TOKEN_ACCURACY = 'token_accuracy'\n",
            "    TOP_K_PREDICTIONS = 'top_k_predictions'\n",
            "    TRAINING = 'training'\n",
            "    TRAIN_MEAN_LOSS = 'train_mean_loss'\n",
            "    VALIDATION = 'validation'\n",
            "    VECTOR = 'vector'\n",
            "    WIDTH = 'width'\n",
            "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
            "    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192...\n",
            "    logger = <Logger ludwig.visualize (ERROR)>\n",
            "    logging_level_registry = {'critical': 50, 'debug': 10, 'error': 40, 'i...\n",
            "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
            "    visualizations_registry = {'binary_threshold_vs_metric': <function bin...\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.6/dist-packages/ludwig/visualize.py\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os2jj4KRCEW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}